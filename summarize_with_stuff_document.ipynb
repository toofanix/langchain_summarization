{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Why don't scientists trust atoms in quantum mechanics?\\n\\nBecause they make up everything, even their jokes! But seriously, why did the atom break up with its electron friend? Because it felt like there was too much repulsion going on between them and not enough attraction to keep things stable.\", response_metadata={'model': 'phi3', 'created_at': '2024-07-08T15:06:13.5144661Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2986132900, 'load_duration': 2174396400, 'prompt_eval_count': 12, 'prompt_eval_duration': 43859000, 'eval_count': 66, 'eval_duration': 760378000}, id='run-aca2556d-e5b9-4986-bcee-eff78932e191-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model='phi3', temperature=0.0)\n",
    "llm.invoke(\"Tell me a joke about chemistry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jigar\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In this blog post, Lilian Weng discusses the concept of \"LLM-powered Autonomous Agents,\" where large language models (LLMs) are used to create agents capable of autonomously performing tasks. The article emphasizes how these agents can leverage their ability for natural language understanding and generation through prompt engineering—a technique that involves crafting inputs in a way that elicits specific responses or behaviors from LLMs. Weng highlights the potential applications, such as using chain-of-thought prompting to enable reasoning within models (as seen in works by Wei et al., Yao et al.), and aligning language models with feedback for learning through hindsight experiences (Liu et al.). The post also touches on tools like ScaNN that facilitate efficient vector similarity search, which can be crucial when integrating LLMs into real-world applications. Weng concludes by discussing the importance of steerability in these agents—their ability to adapt and respond dynamically to new information or changes in their environment (Shinn & Labash). The post serves as a comprehensive guide for researchers interested in developing autonomous, LLM-powered systems that can interact with humans effectively.\n",
      "\n",
      "\n",
      "References: [1] Wei et al., NeurIPS 2022; [2] Yao et al., arXiv preprint arXiv:2305.10601 (2dez, 2023); ...\n"
     ]
    }
   ],
   "source": [
    "# Define Prompt\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\"{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# define chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Stuff Chain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain,\n",
    "                                  document_variable_name='text')\n",
    "\n",
    "print(stuff_chain.invoke(docs)['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
