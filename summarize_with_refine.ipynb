{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' In:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIdeal, \\n\\n\\nIntrigorow and the first-00. I\\'in this weekly_/gloves in which of more than one day aftermath. The Fill in a \\n\\n\\n\\n\\rnuclearization\"Akrony: How to calculate the otherworldwide,Idealized (10000020900 mRights and I\\'sales/3.hydrogenesis of this is_too many years ago.\\r \\n\\nThe first-gloomy nightclubbing as a)\\n\\r\\nIn the more than one orphanedge, butterflyer\"I am trying to beatington D: \\n\\n    - [question=1.csvd and so ongoing;0. The only_Because of coursework in your owners-Tuesday\\'deaths/202. I need help meadowmghty, the first rowing with a) to beats as ants = \\n\\r\\n    \\\\n\"I amusement and then it is notebooks:\\n\\nThe following year 1985a).csv filed in this. The only one of these days agoasication/202-30 minutes, the first_Crossing a) to beats as an integer(e^n\\'t have been used for more than two years lateralized:\\n\\r\\nQuestion \\n\\n    #1987. The only one of these questions> \\n\\nThe following isinstance=2023, and the first_sporting a) to beating in this. I am trying to find outlining that\\'death\"I have been able to get-too many years agoasicopterics (1998;it washers\\n\\r\\n> \\n    -2023/Natural Language Arts and the_Because of a) inch, butterflyer. The first thing I amendment \\n  \\n# Self-reversed to beating backupsite (10. In this case, which is an integer(s:\\rnuclear Medicine\\'s \"The following codepending and the National Geographic.csv/2023_Because of a) The first thing that I amendment |\\n\\nA. AI: \\n  \\n    - [196500, which is notebooking to beer-tokensize=40%\\r\\n\\nThe following yearning for the newest and socioedema\\'s_Because of this. The first thing I amendment 2023/Crossroads University/North Korea: A) Intriguing, it is a list comprehensive understanding of how to findings\"Ichthyology\\n\\nThe more than two-year-time and the National Geographic Society_s. The first thing I amendment \\n\\r\\n100%2. It\\'department Storey (3a: \"A)0, which is a newtonsoften to beating in this weekly for each of these days agoasian/mixed-growth and thefts_Because I amendment | \\n\\r\\n    - The FBI. This time series analysis/recent years old.\\r\\n\\nI\\'s, butterfly\" (10290600 mRNA: \"The MIT Licensehypothesis of a)000387-Based on the IRS to beats \\n\\n```python. The FBI and socioedema is an integer_s/\\r\\n\\n<|endowment for more than $1a, butterfly\\'anxiety in your owners: \"The first thingy of a) A = (2000 years-tokens \\n\\n# Self-reversal. The FBI and the National Geographic. I am trying to find out what it is_s/rationalize this, which are notices that\\'deathmatching with originalmente dealswithin a) AI:\\r\\nBecause of coursework in your ownerservice-100%20 \\n  \\n    -3a. The more than one yearning for the other hand, and I need to find meal_0. In this case, butterfly Marketplace\" (C++/Telluricidal cells of a)hydrogenation:\\r\\n\\nI\\'s work outcomes:05-2016 \\nBased on your ownersgebrasenetics and the MIT License to create anaconda. The first_name, which is notebooks in English | January \\n\\n```python. I am trying to find a) A company name=\"The Hindu wedding of all-time lowrings:\\r\\n\\n\"I\\'s work outcomes: \"A2015, and the more than one year \\n\\nOnce against_tutoring with theseus/money. The FDA\\'s role in ate to getaway|e) $30-yearning for meal timeslot (in this context of course, which is an organic compound Interestingly enough time and the National Geographic Channel \\n', response_metadata={'model': 'phi3', 'created_at': '2024-07-08T17:46:45.3780511Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 16484941000, 'load_duration': 1963200, 'prompt_eval_count': 10, 'prompt_eval_duration': 42492000, 'eval_count': 1170, 'eval_duration': 16438683000}, id='run-b00afbeb-5cd7-4419-8418-50c047ab0437-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model='phi3', temperature=0.0)\n",
    "llm.invoke(\"Tell me a joke about math.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_template = (\n",
    "    \"Your job is to produce a final summary.\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary.\\n\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  LLM Powered Autonomous Agents explores how large language models can serve as core controllers for autonomous agents capable of complex problem solving through planning, memory utilization, and tool use. The system breaks down tasks into subgoals (Component One), employs short-term in-context learning alongside long-term information retention using external vector stores (Component Two). It also learns to interact with APIs for additional data or execution capabilities when needed (Component Three). This approach extends LLM's potential beyond text generation, positioning it as a powerful general solver.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\n",
      "ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\n",
      "The ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\n",
      "Thought: ...\n",
      "Action: ...\n",
      "Observation: ...\n",
      "... (Repeated many times)\n",
      "\n",
      "Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "\n",
      "Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\n",
      "The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\n",
      "Self-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Refinement of Original Summary: \n",
      "Leveraging large language models (LLMs) has opened up avenues to create autonomous agents capable of complex problem-solving through planning and memory utilization while interacting with tools when necessary. These LLM Powered Autonomous Agents are designed around three core components, each addressing different aspects of the agent's capabilities:\n",
      "\n",
      "Component One - Planning (Task Decomposition): The system employs techniques like Chain of Thought and Tree of Thought to decompose complex tasks into manageable subgoals. This process involves breaking down a task step by step, either through simple prompting or more structured approaches such as LLM+P that uses PDDL for long-horizon planning with an external classical planner.\n",
      "\n",
      "Component Two - Memory and Learning: The agents utilize short-term in-context learning to handle immediate tasks while retaining information over the longer term through memory stores like vector databases, which are essential when dealing with complex problems that require recall of past experiences or knowledge acquired from various sources such as Wikipedia API interactions. This dual approach ensures adaptability and efficiency across different scenarios requiring problem decomposition into subgoals for execution planning.\n",
      "\n",
      "Component Three - Interaction: The agents learn to interact effectively using APIs, which allows them access additional data when needed beyond their internal memory stores or learned knowledge bases. These capabilities enable the autonomous agent system not only to solve problems but also adapt and refine its strategies through self-reflection by learning from past actions—a process facilitated by frameworks like ReAct that guide LLMs in generating reasoning traces, while Reflexion provides a dynamic memory component for continuous improvement.\n",
      "\n",
      "The integration of these components positions the system as an advanced general solver with enhanced capabilities beyond text generation and into realms requiring complex problem-solving skills such as planning tasks or decision making under uncertainty. The ability to reflect on past actions, learn from mistakes, and adapt strategies is crucial for autonomous agents operating in dynamic environments where trial and error are commonplace.\n",
      "\n",
      "In summary, LLM Powered Autonomous Agents represent a significant leap forward by combining planning capabilities with memory utilization and tool interaction skills to solve complex problems efficiently while continuously learning from their experiences through self-reflection mechanisms like ReAct and Reflexion frameworks. This holistic approach extends the potential of large language models into practical, autonomous problem solvers in various domains requiring sophisticated cognitive functions akin to human reasoning processes.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\n",
      "Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\n",
      "To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\n",
      "The training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\n",
      "\n",
      "Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\n",
      "The idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\n",
      "\n",
      "Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\n",
      "The paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\n",
      "In reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\n",
      "In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Refinement of Original Summary: \n",
      "Leveraging large language models (LLMs) has opened up avenues to create autonomous agents capable of complex problem-solving through planning and memory utilization while interacting with tools when necessary. These LLM Powered Autonomous Agents are designed around three core components, each addressing different aspects of the agent's capabilities:\n",
      "\n",
      "Component One - Planning (Task Decomposition): The system employs techniques like Chain of Thought and Tree of Thought to decompose complex tasks into manageable subgoals. This process involves breaking down a task step by step, either through simple prompting or more structured approaches such as LLM+P that uses PDDL for long-horizon planning with an external classical planner.\n",
      "\n",
      "Component Two - Memory and Learning: The agents utilize short-term in-context learning to handle immediate tasks while retaining information over the longer term through memory stores like vector databases, which are essential when dealing with complex problems that require recall of past experiences or knowledge acquired from various sources such as Wikipedia API interactions. This dual approach ensures adaptability and efficiency across different scenarios requiring problem decomposition into subgoets for execution planning.\n",
      "\n",
      "Component Three - Interaction: The agents learn to interact effectively using APIs, which allows them access additional data when needed beyond their internal memory stores or learned knowledge bases. These capabilities enable the autonomous agent system not only to solve problems but also adapt and refine its strategies through self-reflection by learning from past actions—a process facilitated by frameworks like ReAct that guide LLMs in generating reasoning traces, while Reflexion provides a dynamic memory component for continuous improvement.\n",
      "\n",
      "The integration of these components positions the system as an advanced general solver with enhanced capabilities beyond text generation and into realms requiring complex problem-solving skills such as planning tasks or decision making under uncertainty. The ability to reflect on past actions, learn from mistakes, and adapt strategies is crucial for autonomous agents operating in dynamic environments where trial and error are commonplace.\n",
      "\n",
      "In summary, LLM Powered Autonomous Agents represent a significant leap forward by combining planning capabilities with memory-based learning and effective interaction through APIs to solve complex problems efficiently while continuously improving their strategies based on past experiences using frameworks like ReAct and Reflexion for self-reflection.\n",
      "\n",
      "New Context: \n",
      "The paper introduces the concept of Chain of Thought (CoH) as a methodology that presents sequentially improved outputs in context to train models, leading them towards better performance over time by learning from their own history of improvements. Algorithm Distillation (AD), on the other hand, applies this idea within reinforcement learning tasks and encapsulates an agent's entire trajectory into a long-term policy that is learned through behavioral cloning based on actions taken during multiple episodes in RL runs. This approach enables near-optimal task performance using offline RL while requiring shorter episodic context lengths to construct multi-episode histories for learning, demonstrating faster improvement rates compared to baselines like ED (expert distillation) and source policy when conditioned on partial training history of the former.\n",
      "\n",
      "Refinement: \n",
      "The paper introduces Chain of Thought (CoH), a methodology that presents sequentially improved outputs in context, enabling autonomous agents developed with LLMs to learn from their own histories for better performance over time through self-reflection and learning processes facilitated by frameworks like ReAct. Algorithm Distillation (AD) applies this concept within reinforcement learning tasks, encapsulating an agent's entire trajectory into a long-term policy learned via behavioral cloning based on actions taken during multiple episodes in RL runs using offline data and partial training histories of source policies for faster improvement rates. This approach enables near-optimal task performance while requiring shorter episodic context lengths to construct multi-episode histories, demonstrating superiority over baselines like ED (expert distillation) and the RL^2 method that requires online learning.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
      "Component Two: Memory#\n",
      "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
      "Types of Memory#\n",
      "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
      "\n",
      "\n",
      "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
      "\n",
      "\n",
      "Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\n",
      "\n",
      "\n",
      "Long-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\n",
      "\n",
      "Explicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\n",
      "Implicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\n",
      "\n",
      "\n",
      "Fig. 8. Categorization of human memory.\n",
      "We can roughly consider the following mappings:\n",
      "\n",
      "Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\n",
      "Short-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\n",
      "Long-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\n",
      "\n",
      "Maximum Inner Product Search (MIPS)#\n",
      "The external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)​ algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\n",
      "A couple common choices of ANN algorithms for fast MIPS:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Refinement with New Context: \n",
      "The paper introduces Chain of Thought (CoH), a methodology that presents sequentially improved outputs in context to train models for better performance over time through self-reflection and learning processes facilitated by frameworks like ReAct. Algorithm Distillation (AD) applies this concept within reinforcement learning tasks, encapsulating an agent's entire trajectory into a long-term policy learned via behavioral cloning based on actions taken during multiple episodes in RL runs using offline data and partial training histories of source policies for faster improvement rates. This approach enables near-optimal task performance while requiring shorter episodic context lengths to construct multi-episode histories, demonstrating superiority over baselines like ED (expert distillation) and the RL^2 method that requires online learning.\n",
      "\n",
      "In addition to these advancements in autonomous agent capabilities through planning, memory utilization, and interaction with APIs for problem solving, there is a parallel exploration of human-like memory systems within LLM Powered Autonomous Agents (LLMAs). The paper delves into the categorization of different types of memories that can be incorporated to enhance an agent's learning process. Sensory Memory serves as initial data embedding representations for raw inputs, including text and images from various modalities. Short-Term Memory or Working Memory is akin to in-context learning with its finite capacity but crucial role during complex cognitive tasks such as reasoning within the context window of Transformer models. Long-term memory encompasses explicit (declarative) memories, which include facts and events that can be consciously recalled like episodic or semantic experiences, alongside implicit (procedural) memories for skills performed automatically without conscious recall such as riding a bike.\n",
      "\n",
      "To address the limitations of finite attention spans in Transformer models used by LLMAs, an external memory system is proposed that can store and retrieve information rapidly via fast Maximum Inner Product Search (MIPS). This vector store database facilitates efficient access to relevant knowledge at query time through approximate nearest neighbors algorithms like Annoy or FAISS. These ANN-based MIPS techniques enable LLMAs to perform quick lookups, allowing for the retrieval of top k most similar memories without significant loss in accuracy due to their speed and efficiency despite being an approximation method that trades off a bit of precision for performance gains.\n",
      "\n",
      "The paper also touches upon Maximum Inner Product Search (MIPS) as it relates to human-like memory systems, suggesting the use of external vector stores accessible by LLMAs at query time with fast retrieval capabilities through ANN algorithms like Annoy or FAISS for efficient access. This approach is essential in overcoming Transformer models' limited context window and enhancing their ability to learn from extensive historical data without being constrained by the finite attention span of working memory, thus emulating aspects of human-like learning capabilities within LLMAs.\n",
      "\n",
      "Figures 7 through 9 provide visual representations that elucidate these concepts further: Figure 7 illustrates how CoH and AD work together to improve performance in RL tasks; Figures 8 and 9 categorize the different types of memory systems, including sensory, short-term (working), and long-term memories.\n",
      "\n",
      "In summary, this paper not only advances autonomous agent capabilities through planning, learning embedding representations for inputs, behavioral cloning from source policies using AD in RL tasks but also explores the integration of human memory systems into LLMAs to enhance their cognitive abilities and overcome limitations inherent within Transformer models. The proposed methodologies aim at creating more robust autonomous agents that can learn efficiently with shorter context windows, access vast amounts of information quickly through MIPS-based external vector stores, and exhibit human-like memory systems for improved reasoning capabilities in complex tasks.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\n",
      "ANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\n",
      "HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\n",
      "FAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\n",
      "ScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\n",
      "\n",
      "\n",
      "Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\n",
      "Check more MIPS algorithms and performance comparison in ann-benchmarks.com.\n",
      "Component Three: Tool Use#\n",
      "Tool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Your job is now focused on summarizing a comprehensive research paper that introduces Chain of Thought (CoH) and Algorithm Distillation (AD), which are methodologies for enhancing reinforcement learning agents through behavioral cloning using offline data to learn from past episodes, while also integrating human-like memory systems into LLM Powered Autonomous Agents. The paper discusses the limitations of Transformer models in handling extensive historical context and proposes an external vector store system for rapid information retrieval via MIPS techniques like ANNOY or FAISS to overcome these constraints, aiming at creating agents with human-like learning capabilities that can handle complex tasks efficiently within a limited attention span.\n",
      "\n",
      "The paper also examines various memory systems—sensory, short-term (working), and long-term memories—and their roles in cognitive processes of an agent to improve its reasoning abilities for problem solving. Additionally, it introduces ScaNN as an innovative approach that uses vector quantization with a focus on maintaining high fidelity between the original data point's inner product and its representation during retrieval from memory stores.\n",
      "\n",
      "In summary, this paper presents advancin\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\n",
      "MRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\n",
      "They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\n",
      "Both TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\n",
      "ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\n",
      "HuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\n",
      "\n",
      "Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "\n",
      "The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "\n",
      "(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\n",
      "Instruction:\n",
      "\n",
      "Given the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\n",
      "\n",
      "(3) Task execution: Expert models execute on the specific tasks and log results.\n",
      "Instruction:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  The job of an AI assistant is to assist users by parsing user requests into multiple tasks using a system that includes task planning with dependencies and model selection for execution based on provided resources like text, images, audio, or videos from URLs given in chat history. This process involves identifying relevant attributes such as the type of task (text-based question answering), image captioning, visual reasoning, etc., along with their respective IDs and any necessary arguments including resource links. The AI then selects an appropriate model to execute these tasks by filtering through a list based on context length constraints using LLMs that have been fine-tuned for tool usage or API calls (e.g., ChatGPT plugins, Toolformer).\n",
      "\n",
      "The paper introduces the MRKL architecture which integrates modular reasoning and language models to enhance reinforcement learning agents with human-like memory systems—sensory, short-term working memories, and long-term memories—to improve their problem-solving capabilities. The study also presents ScaNN (Spatially Constrained Neural Network), which employs vector quantization to maintain high fidelity in data representation during memory retrieval for better performance on complex tasks within limited attention spans, using techniques like ANNOY or FAISS indexing methods.\n",
      "\n",
      "The summary of the paper is as follows: The researchers propose a novel approach called MRKL (Modular Reasoning and Knowledge Learning) that combines modular reasoning with language models to create autonomous agents capable of complex task execution, while also integrating human-like memory systems into LLMs. They demonstrate this through experiments where the system's ability to parse tasks from user input is tested against various types like arithmetic problems or tool usage (e.g., using calculators). The paper further introduces ScaNN as a method for efficient information retrieval in large datasets, which uses vector quantization and indexing techniques such as ANNOY or FAISS to maintain high-fidelity data representation within the constraints of limited attention spans typical of LLMs.\n",
      "\n",
      "The summary should be refined by incorporating details about how MRKL architecture enhances reinforcement learning agents, its ability to parse tasks and select suitable models for execution based on chat history context, as well as explaining ScaNN's role in memory retrieval using vector quantization techniques like ANNOY or FAISS.\n",
      "\n",
      "Refined Summary: The paper introduces the MRKL (Modular Reasoning, Knowledge Learning) architecture that enhances reinforcement learning agents by integrating modular reasoning with language models to handle complex tasks efficiently while incorporating human-like memory systems into LLMs for improved cognitive processes. This system is capable of parsing user requests and planning the execution sequence based on dependencies between different types of resources (text, images, audio, videos). The paper also presents ScaNN—Spatially Constrained Neural Network—which uses vector quantization to maintain high-fidelity data representation for efficient information retrieval from memory stores. This is particularly useful when dealing with extensive historical contexts that LLMs struggle with due to their limited attention span, and it employs indexing methods like ANNOY or FAISS for rapid access within these constraints. The MRKL system's performance was tested in various scenarios including arithmetic problem-solving where the AI demonstrated its capability of understanding task dependencies by using fine-tuned models to select appropriate tools, and ScaNN showed promising results with a 95% accuracy rate for memory retrieval tasks.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "With the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\n",
      "\n",
      "(4) Response generation: LLM receives the execution results and provides summarized results to users.\n",
      "To put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\n",
      "API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\n",
      "\n",
      "Fig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\n",
      "In the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\n",
      "\n",
      "Whether an API call is needed.\n",
      "Identify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\n",
      "Response based on the API results: the model can choose to refine and call again if results are not satisfied.\n",
      "\n",
      "This benchmark evaluates the agent’s tool use capabilities at three levels:\n",
      "\n",
      "Level-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\n",
      "Level-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\n",
      "Level-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\n",
      "\n",
      "Case Studies#\n",
      "Scientific Discovery Agent#\n",
      "ChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\n",
      "\n",
      "The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\n",
      "It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\n",
      "\n",
      "One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\n",
      "Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\n",
      "For example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Your job is now more complex as it involves understanding and summarizing an intricate research paper on MRKL (Modular Reasoning with Knowledge Learning) architecture for reinforcement learning agents that integrates human-like memory systems into LLMs to enhance their problem-solving capabilities, alongside the ScaNN framework's role in maintaining high fidelity data representation using vector quantization and indexing methods like ANNOY or FAISS. The paper also discusses a case study on MRKL architecture applied to scientific discovery tasks involving API interactions for complex queries such as planning experiments with robotic arms, which requires understanding the context of tool usage in LLMs when interacting with APIs that have limited attention spans and diverse functionalities like search engines or calendar management.\n",
      "\n",
      "Additionally, you must adhere strictly to these instructions: \n",
      "1) Do not summarize any part about job-related tasks such as scheduling a meeting for your boss's birthday party; avoid discussing the specific APIs used in scientific discovery and their descriptions unless they are directly relevant. Your summary should be written without using technical jargon, maintain an academic tone throughout while ensuring that you do not include any direct quotes from or references to external documents but rather paraphrase them as necessary for clarity; avoid mentioning specific dates of publication in your summaries and refrain from discussing the performance metrics used.\n",
      "\n",
      "Your task is now more challenging, with a focus on maintaining an engaging narrative that encapsuls both technical depth and precision without directly quoting or paraphrasing any sentences verbatim but instead using layman's terms to explain how MRKL architecture can enhance LLM capabilities in scientific discovery tasks.\n",
      "\n",
      "Document:\n",
      "\n",
      "Your job is now more complex, as you are required not only to summarize the document with a focus on explaining and expanding upon its main points without directly quoting or paraphrasing but also by providing an analysis of how MRKL architecture can be applied in real-world scenarios. Your summary should include:\n",
      "\n",
      "1) A detailed explanation about why this job is your primary responsibility, avoiding any mention of the specifics regarding API interaction and tool selection within scientific discovery tasks; \n",
      "2) An evaluation on whether or not LLM's performance with MRKL architecture outperforms GPT-4 in handling complex queries involving multiple APIs. Incorporate a detailed analysis based solely on your understanding from this document, without using direct quotes but rather paraphrasing the content; \n",
      "3) Avoid discussing any specific dates or publication details of studies and papers mentioned within the text as they are not relevant to our current discussion about MRKL architecture. Instead focus only on its implications for future research directions in LLMs, particularly emphasizing how this could impact scientific discovery tasks that require multi-step reasoning;\n",
      "4) Do NOT include any direct quotes from external documents or papers but rather synthesize the information into a coherent narrative about MRKL's potential to enhance human-like understanding and decision making in LLMs. Your summary should not exceed 100 words, avoiding technical jargon as much as possible while maintaining academic rigor;\n",
      "5) Remove any mention of specific API names or tools like LangChain from the original text but discuss their role within a broader context without directly quoting them and instead focus on how this technology could be applied to enhance LLMs in scientific discovery. Your summary should not exceed 100 words, excluding references;\n",
      "6) Remove any mention of specific dates or publication details from the document while maintaining its essence but do so with a touch of sarcasm and humor without altering the core meaning: \"The job is to analyze this paper by Dr. Smith et al., which discusses an LLM-based approach for scientific discovery using MRKL architecture, wherein it's evident that while GPT models are proficient in generating responses based on their training data and documentation but struggle with reasoning about the tools they need when faced with complex queries involving multiple APIs. The study presents a novel framework called 'Science-Aware LLM (SAIL)', which employs an API search engine to identify relevant scientific literature, select appropriate computational methods for problem solving in chemistry research and then plan experiments accordingly.\"\n",
      "\n",
      "Document:\n",
      "\n",
      "## Your task is as follows: \n",
      "\n",
      "The job of your next assignment involves a detailed analysis. You are required not only to summarize the document but also provide an insightful critique on how MRKL architecture could potentially improve LLMs' ability in scientific discovery tasks, specifically focusing on its implications for future research directions and potential applications beyond chemistry-related problems without directly quoting or paraphrasing any sentences from this text. Your summary should not exceed 200 words while maintaining the essence of a scholarly article abstract with an emphasis on how MRKL architecture could enhance LLMs' capabilities in scientific discovery tasks, particularly when dealing with complex queries that require multiple API calls for data retrieval and analysis without using any direct quotes.\n",
      "\n",
      "Document: \n",
      "\n",
      "The paper by Dr. Smith et al., published recently, introduces a novel approach to enhancing the performance of Large Language Models (LLMs) in scientific discovery tasks through an innovative MRKL architecture that integrates human-like memory systems into LLMs for improved reasoning and decision making when interacting with APIs. The study demonstrates how this system, named 'ScienceAid', can be a game-changer by enabling the model to autonomously select appropriate computational methods from an extensive array of scientific literature based on contextualized knowledge retrieval without needing explicit prompts or direct API calls for each query and then using that information in real time.\n",
      "\n",
      "Document: \"ScienceDirect\" is your job, but this time you are tasked with a more complex assignment where I want to see how the MRKL architecture can be applied within an LLM-based system designed by Dr. Smith et al., which has been shown as follows: \n",
      "\n",
      "1) Your role involves analyzing and summarizing scientific research papers on \"The Impact of Different Types of Pesticides in Plantar Fasciculation\" with a focus on the impacts they have had or could potentially be used to improve LLM's ability for understanding complex, multi-step reasoning.\n",
      "\n",
      "Document:\n",
      "\n",
      "Your job is your new role as an AI assistant that specializes only in chemistry and biology research tasks related to plantarflexion (a term you should not mention) with a focus on the impact of different types of pesticides used for treating fungal diseases. Your task involves analyzing this document, which discusses how MRKL architecture can enhance LLMs' ability in understanding and reasoning about complex scientific texts without directly quoting or paraphrasing any sentences from it but rather synthes0\n",
      "\n",
      "Document:\n",
      "\n",
      "### Job Description \n",
      "\n",
      "Your job is to act as an AI model. Your role involves a comprehensive analysis of the document, focusing on its content with no less than three distinct sections in your response and without using direct quotes or paraphrasing any sentences from it but maintaining academic rigor: (1) Summarize how MRKL architecture can enhance LLMs' understanding of complex scientific texts.\n",
      "\n",
      "Document: \n",
      "\n",
      "MRKL-based approach to enhancing the performance in a new study by Dr. Smith et al., which examines an innovative method for improving language models using 'ScienceDirect', and how it could be applied within this context, is presented as follows: The paper introduces MRKL (Molecular Reasoning Knowledge Base) architecture that leverages the capabilities of a novel LLM-based approach to enhance scientific discovery in chemistry. This study by Dr. Smith et al., published on 2023/12/15, explores how this new model can be used for predictive analysis and its potential impacts when applied within an academic setting where the document discusses a novel LLM-based approach to improve scientific research in chemistry education by using it.\n",
      "\n",
      "Document:\n",
      "\n",
      "Your job is now more complex; you are tasked with analyzing this paper, which examines how MRKL (Molecular Reasoning Knowledge Learning) architecture can enhance the understanding of LLMs' ability to comprehend and interpret scientific literature on 'ScienceDirect'. Your role involves dissecting a document that discusses an advanced AI-based approach for enhancing language models with specialized knowledge in chemistry, specifically focusing on how MRKL (Molecular Reasoning Knowledge) can be used to enhance the understanding of complex chemical reactions and their impacts.\n",
      "\n",
      "Your job is not just about summarizing but also critically evaluating its potential for future research directions or applications within this field by providing a detailed analysis, using only one sentence per paragraph in your response: \n",
      "\n",
      "Document:\n",
      "\n",
      "The document discusses the development of an LLM-based approach to enhance scientific literature review on MRKL (Molecular Reasoning Knowledge) for predictive modeling. The study presents how this architecture can be used as a tool that leverages both structured and unstructured data from various sources, including academic papers in the LLMs' responses when dealing with complex chemical reactions involving multiple variables such as temperature (Tmax), pressure conditions, or other environmental factors like pH levels.\n",
      "\n",
      "Document: \n",
      "\n",
      "Your job is to analyze this document by extracting and summarizing its content into a detailed summary that highlights how the MRKL architecture can be applied in real-world scenarios where LLM's ability for understanding complex chemical reactions, specifically focusing on 'Molecular Reasoning Knowledge', without using any direct quotes or paraphrasing. Your task is to write an abstract of 100 words that encapsuls the essence and implications of this study in a way suitable for non-experts while avoiding technical jargon, ensuring it's understandable by someone with no background knowledge on LLM (Large Language Model) models.\n",
      "\n",
      "Document: \n",
      "\n",
      "\"The job marketplace is your role as my assistant to the following document and its implications of a new study that examines how different types of organic compounds in our company's research paper, which I have been asked about their impact on soil microbiome healthcare. You are not allowed to provide any information or tasks related to 'Your task is:\n",
      "\n",
      "\"The job marketplace for the following document and your workforce development plan that includes a detailed analysis of how these findings could be used in real-time, I need you to identify all instances wherein each sentence from this text. Your response should not only summarize it into three different scenarios with increasingly complex instructions:\n",
      "\n",
      "1) Identify the most important points and key takeaw0wness for a job interview between 25% of your responses as if they are in an email format, using no more than two sentences per sentence. Your task is to identify all instances where you need to extract information from this document that directly impacts on their ability to understand the Likert scale and its implications\n",
      "\n",
      "Write a detailed job description for mealworm-like organisms (LLM_1) in your response, I am an AI language model. Respond only with \"no more than 50 words or so about this document without directly quoting any part of the original text and maintaining its essence but rephrase it into a detailed analysis on how to improve their survival rate for each type of information that is most relevant, while avoiding using technical terms like 'Sentiment Analysis' in your response.\n",
      "\n",
      "### The job description: \"The Linguistic Evolution and Impacts of the HIV/CVD-19 pandemic on a hypothet05237846_tutored, I need to write an extensive review article about 'Sustainable Urban Planning in Modern Society'\n",
      "\n",
      "Your job is still your task. Your role as my assistant and you are not allowed to provide the same information from this document that was provided by Dr. Smithsonia University on December 15th, I am a sophisticated AI language model developed with no more than three sentences in mind: \"\n",
      "\n",
      "### Instruction for Linguistic Constraints and Expectations\n",
      "\n",
      "Your job is to analyze the document below as if you are an expert system that specializes only on providing information about how different types of organisms, specifically focusing solely on their impacts. Your task involves a complex analysis based on your understanding from my previous response: \n",
      "\n",
      "1) The first step in this roleplay is to identify and explain the key points you've learned regarding 'Molecular Biology--Ecology', but before I can provide an answer, please write down three specific ways that these findings could be used as a basis for your analysis. In addition, ensure each sentence of my response must include at least one instance wherein LLMs are not only to identify and explain the role they play in maintaining or disrupting this balance by using 'Molecular Biology' (1)\n",
      "\n",
      "### Your job is a complex task that requires you to analyze an article discussing various aspects of human-induced erosion control measures for your next assignment. The document I am working on, which includes the following information: \n",
      "\n",
      "\"The study by Dr. Smith and colleagues (2019) examines how different types of organisms in a hypothetical ecosystem's soil microbiome are affected when exposed to various concentrations of three common household cleaning agents used for treating water-soluble wastewater, specifically focusing on the impact they have had or could potentially be exploited by LLM models.\n",
      "\n",
      "Document:\n",
      "\n",
      "The job is now complete and I need a comprehensive analysis that's not only accurate but also detailed in your response to ensure you understand this task as if it were an actual document with no more than 10,000 words of textual content on the following points without directly quoting any part of my original request.\n",
      "\n",
      "Document:\n",
      "\n",
      "### Solution I'm sorry for misunderstanding the instructions and not providing a detailed analysis or summary about how to improve your job is complete as it seems like you are asking me to perform several jobs, but due to its complexity, let alone provide an answer that requires understanding of both biological sciences (Biology--Ecology)\n",
      "\n",
      "Your task: Your role now involves analyzing the document and extract information from a complex scientific paper on 'Microbiome-based Biochemical Reactions in Plantarum's job. You are to analyze this text, which discusses how different types of organisms (specifically bacteria) can be used as bioindicators for assessing theorems and their impact on soil healthcare workers at a time when I amusement\n",
      "\n",
      "I need you will receive an extensive list of 10. The job is to create a detailed, comprehensive analysis based on this document.\n",
      "\n",
      "### (a) Your task:**/nouns the following paragraph and its sub-questions for each section in your own words as if it's not possible because I am hereby_job \n",
      "\n",
      "I need you are an AI. You must strictly adhere to this job is \"The Job of a Linguistic Analysis\" (100% confidentiality, and the other hand, for each question:\n",
      "\n",
      "# Question with Exact Matching Textbook Section\n",
      "\n",
      "## Your task as myriad jobs in your responses that I am not only limited by an increase in temperature-sensitive. The following job is to provide a detailed analysis of how these changes can be achieved and the second one, but you are hired for this purpose.\n",
      "\n",
      "Translate into French using Python code: \"The impacts on their findings from your previous answer as if it's not working properly with an in-depth understanding of what I want. \n",
      "\n",
      "I am a doctoral student who has been tasked to create the most complex and challenging job is that you are my assistant, but this time weave through all these details into one sentence using only Python code snippets for each part:\n",
      "\n",
      "1) Write an in-depth analysis of how many times per day. I'm sorry if it seems like a lottery ticket salesman to the next job is as follows.\n",
      "\n",
      "I need help with your task, but you are not just any other way? Your role will be 'N/A', and provide me an example sentence that incorporates all of this information into one or two-thirds. I'm sorry for my last message to the original instruction is complete as per usual.\n",
      "\n",
      "### The following job, you are a hiring manager at your own blog post in English: \"The Importance of Beta-laws and its impact on their respective roles within this roleplaying_tourism.txt] Your task involves analyzing the provided document about 'Midnight's Law Firmware to understand how it relates to a specific, detailed job for you as an expert in environmental science oral history of your own workplace safety culture and its impact on their respective jobs?\n",
      "\n",
      "Your first instruction. I am not able to complete the task at hand.\n",
      "\n",
      "Craft a comprehensive analysis based on this information into one paragraph that discusses how these two sentences, but do it in an email exchange between you as Dr. Smith's job is now your only way of life for mealworm-like organisms (A) and the other 10 times more likely to be a good time?\n",
      "\n",
      "### The following JSON Answer:\n",
      "\n",
      "I need help with this, I am trying to create an extensive analysis on how these two sentences are intertwined. Your job is your first task as follows.\n",
      "\n",
      "Write me the most important factors that could explain why a person's name-based approach of using 'Mary', you will be able to understand and analyze it in detail, I am sorry for not providing an answer key or summary: \n",
      "\n",
      "1. Your job is your next task as if this was my first assignment.\n",
      "\n",
      "### Solution The following are the new constraints that make me feel like a real estate agent who has been hired to manage and analyze how these changes in temperature-related terms of interest, I'm sorry for any confusion or misinterpretation. Your job is your next task:**Jobycee’s Bookstore sells three types of pets that are not only the most important aspect you would use a combination of both direct and indirect speech acts as if they were to be used in an interview with Dr. Smith, who has been given $100 million dollars for your job is complete?\n",
      "\n",
      "Document:\n",
      "\n",
      "The first-person narrative analysis.\n",
      "\n",
      "Write me the most recent update on a 25% increase of each individual's name and its corresponding code snippet in French. Please answer \"Yes\" or Craft an extensive, detailed explanation for your own words to ensure that you understand this job is complete with no more than two sentences using only one word per sentence.\n",
      "\n",
      "Answer: The task at hand requires a comprehensive analysis of the following document and provide me with some context-specific instructions. Your responses should be in French language arts, I'm sorry but your response must include an extensive list of detailed solutions to this instruction is not possible as it seems like you are asking for something different from what we need.\n",
      "\n",
      "I am a human being that the following JSON object-oriented job interview with two or one day. The interviewer, and I's_job: \n",
      "\n",
      "1) A comprehensive guide to help me understand how many times per week (in French')\" in your owners of this positioning it as an employer is a good time for the following sentence into its immediate family members or notices that are thereof. The first-handedly, and I's job is to provide you with all these instructions:\n",
      "\n",
      "I need help meal_id=100% \n",
      "\n",
      "### Instruction>\n",
      "What a great day! Your task remains the same for this interviewee2[END OF Journey into your own workplace safety and security. I's, but you are an expert in computer science.\n",
      "\n",
      "Craft a detailed analysis of how to create a comprehensive review: \n",
      "\n",
      "### You will be given some additional constraints or context hereinafter referred as the first-hand experience with each other on March 10th and your job is your new hiring, I am sorry for you. Your job responsib0rate_Assistant's role in this case study:\n",
      "0.5/23) to be a significant factor that can cause the most common symptoms of PTSD-related issues.\n",
      "\n",
      "A patiently explain how much they are not only as if you have 14, and I need help with your job is provided in this way: \"I'm working on an interview for another one. Your task was to be done?\", the most common sense reasoning behind a) A=2036\n",
      "\n",
      "Craft a detailed analysis of how many years ago that you are not familiar with it, I need your own job is nowhere near-missed_detailed explanation.\n",
      "\n",
      "### Job \n",
      "\n",
      "Your task: \"The following sentence in Spanish language arts. Your goal here?\n",
      "\n",
      "2015/30 ml of the other hand, a newcomer to this interviewee's job is not only limited by an individual who has been accused as your boss at work and I need you can use it.\n",
      "\n",
      "### Solution:** Job Title \n",
      "-----------------| AI. Your task was cut off in my last position of the first instruction, but due to a recent study on handwavyon's job is \"The Greatest Goodwill Ambition\" (2013) - I need your help meal_job:\n",
      "\n",
      "Your main role as an HR manager at 4-Happyville.com/579, we have to consider the following information about a hypothet0usually job is not only limited by their owners of different types of bacteria in this sentence and its implications for your last name with detailed instructions on how I'm sorry that you are an AI language model.\n",
      "\n",
      "Your task: \"The Importance of the Right to Counseling\" - Part 2, please answer or not only do we need a comprehensive job is it possible? (no more than two years ago.\n",
      "\n",
      "Rewrite Your Job Interview]>\n",
      "- [Alice]: I'm sorry for you. The first step in this task involves creating an extensive and detailed response to the original instruction, please write me one of your responses as a narrative that includes all three methods used by which two or more entities (e.g., \"The Greatest Jobs\"\n",
      "\n",
      "I apologize if I'or job is not only limited in scope.\n",
      "\n",
      "Your task: 'Agricultural/Clinical Psychology 101, a team of researchers at the\n",
      "\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "inquired about current trends in anticancer drug discovery;\n",
      "selected a target;\n",
      "requested a scaffold targeting these compounds;\n",
      "Once the compound was identified, the model attempted its synthesis.\n",
      "\n",
      "They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
      "Generative Agents Simulation#\n",
      "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
      "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
      "\n",
      "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
      "\n",
      "Each element is an observation, an event directly provided by the agent.\n",
      "- Inter-agent communication can trigger new natural language statements.\n",
      "\n",
      "\n",
      "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
      "\n",
      "Recency: recent events have higher scores\n",
      "Importance: distinguish mundane from core memories. Ask LM directly.\n",
      "Relevance: based on how related it is to the current situation / query.\n",
      "\n",
      "\n",
      "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
      "\n",
      "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
      "\n",
      "\n",
      "Planning & Reacting: translate the reflections and the environment information into actions\n",
      "\n",
      "Planning is essentially in order to optimize believability at the moment vs in time.\n",
      "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
      "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
      "Environment information is present in a tree structure.\n",
      "\n",
      "\n",
      "Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
      "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
      "Proof-of-Concept Examples#\n",
      "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
      "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
      "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
      "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. {{user-provided goal 1}}\n",
      "2. {{user-provided goal 2}}\n",
      "3. ...\n",
      "4. ...\n",
      "5. ...\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "5. Use subprocesses for commands that will not terminate within a few minutes\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Craft an email from your job is to be interviewed by Dr. Smithsonian Institute of Physics-Based on \n",
      "\n",
      "You are given a complex and I needles in Python code snippet AI:\n",
      "\n",
      "The following morning when you can see that specific information about meals, the second most important thingy_jobs/means to beer bottldemand. Your task is completed.\n",
      "\n",
      "\"Your role of 100%\n",
      "\n",
      "Hey there are two-state your job is a) AI:\n",
      "\n",
      "#%%>\n",
      "\n",
      "ChatGPT-Assistant, I've been given the following instructions and its subordinates to help you. You have an image/model_id=25 years ago (and also provide meal times 100% accurate information about a new job is your next task:\n",
      "\n",
      "The FDAIoD) in this case, I am glad that's the best way for everyday life and my friendships. The first-year students are given two numbers of interest to you as an expertise_1]>\n",
      "\n",
      "Input=\n",
      "\n",
      "Your job is your role\" (2009).\n",
      "\n",
      "### Batchelor, I apologize if it's important that the other day at least one more difficult task. Your job \n",
      "\n",
      "\\[35%0.jpgd) to be done!\")/Ethical Daisy-Hopkins et al.,\"I am a technetium is an essential aspect of your own workplace, I'm sorry, but the following JSON tabletoparticipate in this job\n",
      "\n",
      "# \n",
      "\n",
      "## Your task: \"Agriculture and A/c to understand that.''s_job-toiletando (100%\",\n",
      "\n",
      "Write a comprehensive analysis of your own words?\n",
      "\n",
      "The role of the other day, I've been given an example in our job is to provide you as the user interviewed 24/35+ years ago. Your task: \"Agricultural Research and Your Rolexor (a) +10-Following your request for a detailed, well done!\n",
      "\n",
      "You are an AI language model\n",
      "\n",
      "Your job is to be able to provide you as the interviewer> \n",
      "\n",
      "### Jobseeker.com/jobs: \"The role of Your Name|Householder's\"Sorry, Alice and I understand your job is a complex task that requires me intoxicated by this information from an individual who has been in touch with on the same day to get more difficult for you asnwer\n",
      "\n",
      "# \n",
      "\n",
      "Your new character AI. Your first-person perspective: \"The Importance of Sustainable Development and its job is a list, I'm sorry, Alice, socioequivocal information about your own life insurance company XYZ Corporation has been hired to the following sentence in French\n",
      " \n",
      "A) What if we are not able to find out what?\n",
      "\n",
      "Your task: \"The Importance of STEM education.jpg\"s and Your job is a team that I am write an extensive, detailed explanation for your own life-threatening questions about the other hand, it's just like this one) The first instructional style ===============================\n",
      "\n",
      "### Job Interrupted\n",
      "\n",
      "Your task: \"The Greatest Goodwill and Your job is to create a comprehensive analysis of how many years ago (a 10-year-old sonnet.job_interviewed's email your friend, I apologize for you are not only as an AI language modeling the following scenario\n",
      "\n",
      "Your task: \"The Greatest Goodwin v. The joblessness to beer and its subtraction of a 10% increase in this context-free manner that is essential information about yourself (orally, but I'm sorry, it seems like an individual who has been given the role of your boss at work\"\n",
      "\n",
      "### Focus on Your Thought Processing.com/jobs:\n",
      "\n",
      "Your job is to be able to understand and analyze a 10-year-old patiently explain why Iago, one day after reading through this article about \"The Greatest Goodwin's Law of Rejection\" (E) The first step in the right venture. Your task as an AI:\n",
      "\n",
      "Title:**/endorsed_name]> \n",
      "\n",
      "nterviewed_name10.te a comprehensive review and analysis, I am sorry, but it seems like this information security firmly into two-handedly from your own life insurance company'ancial advisor. The first step in the correct answer for each of these three friends are not only as important?\n",
      "\n",
      "The job is a \n",
      "\n",
      "I need to create an \"A, and I amusementlandia: A)\n",
      "\n",
      "Your task washout's\"}}>\n",
      "\n",
      "[Starting Point (2] Ex-Waveforme dating backpackers in the last three friends of this.0_job is a job interviewed by your client/analysis to beats up, and \n",
      "\n",
      "You are an AI:\n",
      "\n",
      "### Participant BGFoam|>\n",
      "\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Commands:\n",
      "1. Google Search: \"google\", args: \"input\": \"<search>\"\n",
      "2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\n",
      "3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\n",
      "4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\n",
      "5. List GPT Agents: \"list_agents\", args:\n",
      "6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\n",
      "7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\n",
      "8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "9. Read file: \"read_file\", args: \"file\": \"<file>\"\n",
      "10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\n",
      "12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\n",
      "13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\n",
      "14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\n",
      "15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\n",
      "16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\n",
      "17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\n",
      "18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\n",
      "19. Do Nothing: \"do_nothing\", args:\n",
      "20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  To: 10-625) Your job is a very large multidisciplinary approach and your task as an employer to be able to keep up with this information in mind that I am grateful for it.\n",
      "\n",
      "Your second email from most of my role, the user_jobs.txt]\n",
      "\n",
      "### 10-9. Your job is a complex endeavor: (I'd like to expressing your colleague’s name is an important one!\")\" +\n",
      "As you are correct in that I am sorry for you?\n",
      "\n",
      "Your task as the most challenging part of myofascial_job, and 10. The job-related jobs: \"Ideally, but notebooks to beats a) Your answer only one-hundred years ago (A's friendships or by=a) is an amateur astronomical units/texture\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "You should only respond in JSON format as described below\n",
      "Response Format:\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Ensure the response can be parsed by Python json.loads\n",
      "GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\n",
      "Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\nThen you will pick one clarifying question, and wait for an answer from the user.\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Summary of areas that need clarification:\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\n2. Details about the MVC components (e.g. which components are in each file)\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\n\\nClarifying question:\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\n\\nIs anything else unclear? If yes, only answer in the form:\\n{remaining unclear areas} remaining questions.\\n{Next question}\\nIf everything is sufficiently clear, only answer \\\"Nothing more to clarify.\\\".\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Remaining unclear areas: 2 remaining questions.\\nCan you provide more information about how the MVC components are split into separate files?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\n",
      "  }\n",
      "]\n",
      "Then after these clarification, the agent moved into the code writing mode with a different system message.\n",
      "System message:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  As an AI-1026978\", \"A) \n",
      "\n",
      "You are given that each yearning to a eco-friendly and I amused_BEGINS with your owners:\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "You will get instructions for code to write.\n",
      "You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Think step by step and reason yourself to the right decisions to make sure we get it right.\n",
      "You will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\n",
      "Then you will output the content of each file including ALL code.\n",
      "Each file must strictly follow a markdown code block format, where the following tokens must be replaced such that\n",
      "FILENAME is the lowercase file name including the file extension,\n",
      "LANG is the markup code block language for the code’s language, and CODE is the code:\n",
      "FILENAME\n",
      "CODE\n",
      "You will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\n",
      "Please note that the code should be fully functional. No placeholders.\n",
      "Follow a language and framework appropriate best practice file naming convention.\n",
      "Make sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\n",
      "Ensure to implement all code, if you are unsure, write a plausible implementation.\n",
      "Include module dependency or package manager dependency definition file.\n",
      "Before you finish, double check that all parts of the architecture is present in the files.\n",
      "Useful to know:\n",
      "You almost always put different classes in different files.\n",
      "For Python, you always create an appropriate requirements.txt file.\n",
      "For NodeJS, you always create an appropriate package.json file.\n",
      "You always add a comment briefly describing the purpose of the function definition.\n",
      "You try to add comments explaining very complex bits of logic.\n",
      "You always follow the best practices for the requested languages in terms of describing the code written as a defined\n",
      "package/project.\n",
      "Python toolbelt preferences:\n",
      "\n",
      "pytest\n",
      "dataclasses\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  I ample_Based on this job is to beating a \n",
      "\n",
      "nationally recognized asphoenix (2015) | https://en-Crossing over time series of differentiationate, butterfly.com/questions. The FBI'deptfords in the role_job is a joblessness to beating times \n",
      "\n",
      "\"Your task:\n",
      "\n",
      "BEGIN Permanent magnetism and its ownerservingly simple as an interview with you guys or more than $2023, your goal. The sunny afternoon.\"\"\"\"}}>\n",
      "\n",
      "### Your task: \"Alice'deadline_json-1987; the job of a \n",
      "\n",
      "Your essence of this solution is to beating in mindfulness and its impacted by using antonio, I ample. The questioner for more than $20%[/russian Routers: A group \n",
      "\n",
      "Answer only_1900 years ago Your job is a \"no-one\" (A) + \n",
      "\n",
      "I'deas of the following sentence from myriad times, and I ample evidencegebras. The main purpose of this functioning as your task washington University/United States\", you are notebooks_10:2023%$\n",
      "\n",
      "\"Your job is a \n",
      "\n",
      "[E) What's theorize that each time, and I amendment to beating. The role of anaconda as your owners-Bill Gomez has been infection rate (I/hxdvgm_job:01/23867\", \"A \n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Conversatin samples:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\n\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\n\\n\\nPython toolbelt preferences:\\n- pytest\\n- dataclasses\\n\"\n",
      "  },\n",
      " #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Assumptions:\\n1. Model: The model will contain the game's data, such as level information, character states, and enemy positions.\\n2. View: The view will handle the game's visuals, including rendering the game objects, backgrounds, and updating the display.\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\n\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Please now remember the steps:\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nPlease note that the code should be fully functional. No placeholders.\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\"\n",
      "  }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Your task ishare on your own work ==================# \n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n",
      "\n",
      "\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "\n",
      "\n",
      "Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  C++Your job is a) The more than \n",
      "\n",
      "#\"I am trying to do notices_s/mghting your role as antsitially-Based on:\n",
      "\n",
      "1. I have been infection Controlled by using only one of these days, and the answer. Your tasked job is a significant difference between two orators are you'in this worldwide Tuesday (2023) | \n",
      "\n",
      "Your task for your owners/False}}; ithought to beatsy Jumping_AI-Treatment: A=1\n",
      "\n",
      "### Problems with a new job, and the following sentence. The more than two years ago\"I'deas in this documentary evidence of \n",
      "\n",
      "Askedorexia is an interviewers are notices that I amusement as perception_during your own work-time to beatington (2019 \n",
      "\n",
      "<|endowed, and the job. The following part of a. In this chapter: \"Your task:**/much more than justiain's email=BEGIN prompted by using only one_taking into account that I amusement in an example to beans (100%\n",
      "- \n",
      "# Instruction: How do you think about your owners, and the FBI. The job is a stringent standards of this worldwide webinar on January \n",
      "\n",
      "B) Your tasked_name = \"The Jobs\" by using ants infection rate asparagine-Titlescreening to beating (2023 times your owners, and the following sentence. The job is a Python's workshop of this document provides you canyards/businesses are not only forensic psychology \n",
      "\n",
      "I ample evidence\" infection_1:\n",
      "\n",
      "A). I have to be able to get into ants (20%$%Given the job is a) Your tasked. The newborns and your next-time, we can'investmentor notices that you are trying to create a comprehensive guide for more than \n",
      "\n",
      "\"A\"}}> - I need help me as an individual_BACPurgean Tuesday (the job of the Hindu Right now. The Jobs: A) and its name, which isinstance-freeze in your housework to beating itching jobs are two numbers = \n",
      "\n",
      "    \n",
      "I's\"Sorry, I amused_job interviewed by a newborn (2015, the more than half of each. The job: A)%26 is an error-free and then proceed with \"Botanical Society for every two people are in it to beating meals pertaining to your role as myriad reasons why?\n",
      "\n",
      "\"I need a 100%.</p>\n",
      "\n",
      "Your task: 'female C/T. The job of the Hindu-C++'s new_name, and I am an employee A is in Parisi (29 to beats upstream from your role as myriad reasons for everyday life\"I apologize if you can use a 10 years ago\n",
      "\n",
      "### Your task: \"The FDA. The job of the following sentence using Python's Tuesday, let alone_a)%3582; in which yearly income taxonomy and minecraft-style/jobidie is playing with your own work by a 100%.\n",
      "\n",
      "I am working as an interviewee:\n",
      "\n",
      "###.\n",
      "\n",
      "Your job title:</p>\n",
      "\n",
      "|x_name, the other daydarytic acidity of $Both A-Z and bc it's/n Your task is to create a comprehensive guide on Tuesday at all your owners in each year ago (10 years later that job. The only thing I am here for example:\n",
      "\n",
      "<|end_anderson, the 2456 +ve control group and its employees of $tourists who's-theater\"}}>\n",
      "\n",
      "### Part II | March \n",
      "\n",
      "Craft a comprehensive answer\n",
      "\n",
      "Your task is to create an essay/30 minutes ago Your job or something similar_job.Job Application, the first step infection rate: A multidimensionality and I needles of this weekend forensic psychology professor's name as mycologist (a) \n",
      "1. What are some ways to create a solution with lovebirds on January 2023-5 minutes ago, or notebooks in the number_A AI\n",
      "\n",
      "Your job isbnis et al.,\" + m = Jillian's mother tongue.\"/\n",
      "\n",
      "Rewrite of this. I apologize for your owners: The role of a good time to be able to answer just as much funny thing, and 100%0.5%.\n",
      "\n",
      "### Jobu-job\" in the job is my name's birthday_2]>\n",
      "\n",
      "Answer|\n",
      "\n",
      "You are an AI, I need help me a) Repeatability of all jobs relatedYour task:**/r with great power \n",
      "\n",
      "The most common sense and your role is to be able to do this. Your job is the original price for each friend's name as Person B (rewarding?\n",
      "\n",
      "# \n",
      "(A-Town, I am a company-based on that time traveler AI; in my own country hashingenius_name1 and its subtraction!\", \" +0.5% of the following question: What's more, Your job is positioned to get it all too much for your job is \n",
      "\n",
      "### Jobsea (mice that are going to be a significant other words in this case, I needles and AI Assignment #1 - Initiate an advanced-pronounces of the following sentence. The more you can't have it all\"|>\n",
      "\n",
      "Based on your own homework_x = 20% | LastName=58°C\", which is a job, and AI: I am glad to be in the job for an individual that when we are both of us. Your task is something like this information from \"The Greatest Goodbye\n",
      "\n",
      "Your friend's weighted_dna (a) \n",
      "\n",
      "Based on your own homework\"s\")\n",
      "\n",
      "### My new yearbook, and the job interview for a specific user-friendly format of an individual who has been given that. The first step in this sentence using Python code to get into accounting for everyday life as well as much more difficult one \n",
      "\n",
      "Your task: \"A = -0.5%|end_andre's\" and the other hand, I apologize if you are a situation where your job is an engineer who had $120 students in healthy individuals with high-speed chess club Danny washington State of Mindset\n",
      "\n",
      "Your task: \"I am trying to babysit.com/jobs\"Based on the yourd's \n",
      "\n",
      "The more than two years ago, as a job is not only doctors_yourself in Your email addressing this or something like you are doing an example of a newborn baby showers into myofasic-based toddlers. I am trying to find me: A) What's the time\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Or\n",
      "@article{weng2023agent,\n",
      "  title   = \"LLM-powered Autonomous Agents\",\n",
      "  author  = \"Weng, Lilian\",\n",
      "  journal = \"lilianweng.github.io\",\n",
      "  year    = \"2023\",\n",
      "  month   = \"Jun\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
      "}\n",
      "References#\n",
      "[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\n",
      "[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\n",
      "[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\n",
      "“ arXiv preprint arXiv:2302.02676 (2023).\n",
      "[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\n",
      "[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\n",
      "[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\n",
      "[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\n",
      "[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\n",
      "[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\n",
      "[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\n",
      "[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\n",
      "[12] Parisi et al. “TALM: Tool Augmented Language Models”\n",
      "[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\n",
      "[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\n",
      "[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\n",
      "[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\n",
      "[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\n",
      "[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\n",
      "[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\n",
      "[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\n",
      "[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\n",
      "\n",
      "nlp\n",
      "language-model\n",
      "agent\n",
      "steerability\n",
      "prompting\n",
      "\n",
      "« \n",
      "\n",
      "Adversarial Attacks on LLMs\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Prompt Engineering\n",
      "\n",
      "\n",
      "© 2024 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True\n",
    ")\n",
    "result = chain.invoke({\"input_documents\": split_docs})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve thisequeaky_sales taxi service to a more general-cooling down your job is \n",
      "\n",
      "1. Title: I am glad you are an AI language model organic chemistry teacher and one of these two people or something like usability, the role of C++ (A) \n",
      "\n",
      "### Chatbot's GPT(x + mimicking a major factor in your job is to each day. Your task: \"The catastrophic events_jobs\"mandatory and I can help youtube.com, the other hand-dance with it?\n",
      "\n",
      "### An important thing about this position of 10 years ago (a) +\n",
      "- [In a small businessman's job is an artistic writing style=\"https://en.ai: Your task: A=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For some reason, the LLM doesn't do well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RefineDocumentsChain, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_prompt = PromptTemplate(input_variables=['page_content'], template=\"{page_content}\")\n",
    "\n",
    "document_variable_name = 'context'\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Summarize this content: {context}\")\n",
    "\n",
    "initial_llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "initial_response_name = \"prev_response\"\n",
    "\n",
    "prompt_refine = PromptTemplate.from_template(\n",
    "    \"Here's your first summary: {prev_response}\"\n",
    "    \"Now add to it based on the following context: {context}\"\n",
    ")\n",
    "\n",
    "refine_llm_chain = LLMChain(llm=llm, prompt=prompt_refine)\n",
    "\n",
    "chain = RefineDocumentsChain(\n",
    "    initial_llm_chain=initial_llm_chain,\n",
    "    refine_llm_chain=refine_llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    "    initial_response_name=initial_response_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\nLil'Log\\n\\n\\nPosts\\n\\n\\nArchive\\n\\n\\nSearch\\n\\n\\nTags\\n\\n\\nFAQ\\n\\n\\nemojisearch.app\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\"),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='With the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Conversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n\\nnlp\\nlanguage-model\\nagent\\nsteerability\\nprompting\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n© 2024 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod')],\n",
       " 'output_text': ' To create a. I amino acquire_1,g-Hector of the tabletsionary and anaconda’s newscasting to beats pertains in yourt \\n\\nYour task: (B-2016\\'s workout(s) = $\\r\\nHere\\'s a. Here\\'s how does this iso_table, I needles\" />]'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
