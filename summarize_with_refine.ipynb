{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' In:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIdeal, \\n\\n\\nIntrigorow and the first-00. I\\'in this weekly_/gloves in which of more than one day aftermath. The Fill in a \\n\\n\\n\\n\\rnuclearization\"Akrony: How to calculate the otherworldwide,Idealized (10000020900 mRights and I\\'sales/3.hydrogenesis of this is_too many years ago.\\r \\n\\nThe first-gloomy nightclubbing as a)\\n\\r\\nIn the more than one orphanedge, butterflyer\"I am trying to beatington D: \\n\\n    - [question=1.csvd and so ongoing;0. The only_Because of coursework in your owners-Tuesday\\'deaths/202. I need help meadowmghty, the first rowing with a) to beats as ants = \\n\\r\\n    \\\\n\"I amusement and then it is notebooks:\\n\\nThe following year 1985a).csv filed in this. The only one of these days agoasication/202-30 minutes, the first_Crossing a) to beats as an integer(e^n\\'t have been used for more than two years lateralized:\\n\\r\\nQuestion \\n\\n    #1987. The only one of these questions> \\n\\nThe following isinstance=2023, and the first_sporting a) to beating in this. I am trying to find outlining that\\'death\"I have been able to get-too many years agoasicopterics (1998;it washers\\n\\r\\n> \\n    -2023/Natural Language Arts and the_Because of a) inch, butterflyer. The first thing I amendment \\n  \\n# Self-reversed to beating backupsite (10. In this case, which is an integer(s:\\rnuclear Medicine\\'s \"The following codepending and the National Geographic.csv/2023_Because of a) The first thing that I amendment |\\n\\nA. AI: \\n  \\n    - [196500, which is notebooking to beer-tokensize=40%\\r\\n\\nThe following yearning for the newest and socioedema\\'s_Because of this. The first thing I amendment 2023/Crossroads University/North Korea: A) Intriguing, it is a list comprehensive understanding of how to findings\"Ichthyology\\n\\nThe more than two-year-time and the National Geographic Society_s. The first thing I amendment \\n\\r\\n100%2. It\\'department Storey (3a: \"A)0, which is a newtonsoften to beating in this weekly for each of these days agoasian/mixed-growth and thefts_Because I amendment | \\n\\r\\n    - The FBI. This time series analysis/recent years old.\\r\\n\\nI\\'s, butterfly\" (10290600 mRNA: \"The MIT Licensehypothesis of a)000387-Based on the IRS to beats \\n\\n```python. The FBI and socioedema is an integer_s/\\r\\n\\n<|endowment for more than $1a, butterfly\\'anxiety in your owners: \"The first thingy of a) A = (2000 years-tokens \\n\\n# Self-reversal. The FBI and the National Geographic. I am trying to find out what it is_s/rationalize this, which are notices that\\'deathmatching with originalmente dealswithin a) AI:\\r\\nBecause of coursework in your ownerservice-100%20 \\n  \\n    -3a. The more than one yearning for the other hand, and I need to find meal_0. In this case, butterfly Marketplace\" (C++/Telluricidal cells of a)hydrogenation:\\r\\n\\nI\\'s work outcomes:05-2016 \\nBased on your ownersgebrasenetics and the MIT License to create anaconda. The first_name, which is notebooks in English | January \\n\\n```python. I am trying to find a) A company name=\"The Hindu wedding of all-time lowrings:\\r\\n\\n\"I\\'s work outcomes: \"A2015, and the more than one year \\n\\nOnce against_tutoring with theseus/money. The FDA\\'s role in ate to getaway|e) $30-yearning for meal timeslot (in this context of course, which is an organic compound Interestingly enough time and the National Geographic Channel \\n', response_metadata={'model': 'phi3', 'created_at': '2024-07-08T17:46:45.3780511Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 16484941000, 'load_duration': 1963200, 'prompt_eval_count': 10, 'prompt_eval_duration': 42492000, 'eval_count': 1170, 'eval_duration': 16438683000}, id='run-b00afbeb-5cd7-4419-8418-50c047ab0437-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model='phi3', temperature=0.0)\n",
    "llm.invoke(\"Tell me a joke about math.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_template = (\n",
    "    \"Your job is to produce a final summary.\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary.\\n\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  LLM Powered Autonomous Agents explores how large language models can serve as core controllers for autonomous agents capable of complex problem solving through planning, memory utilization, and tool use. The system breaks down tasks into subgoals (Component One), employs short-term in-context learning alongside long-term information retention using external vector stores (Component Two). It also learns to interact with APIs for additional data or execution capabilities when needed (Component Three). This approach extends LLM's potential beyond text generation, positioning it as a powerful general solver.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\n",
      "ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\n",
      "The ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\n",
      "Thought: ...\n",
      "Action: ...\n",
      "Observation: ...\n",
      "... (Repeated many times)\n",
      "\n",
      "Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "\n",
      "Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\n",
      "The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\n",
      "Self-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Refinement of Original Summary: \n",
      "Leveraging large language models (LLMs) has opened up avenues to create autonomous agents capable of complex problem-solving through planning and memory utilization while interacting with tools when necessary. These LLM Powered Autonomous Agents are designed around three core components, each addressing different aspects of the agent's capabilities:\n",
      "\n",
      "Component One - Planning (Task Decomposition): The system employs techniques like Chain of Thought and Tree of Thought to decompose complex tasks into manageable subgoals. This process involves breaking down a task step by step, either through simple prompting or more structured approaches such as LLM+P that uses PDDL for long-horizon planning with an external classical planner.\n",
      "\n",
      "Component Two - Memory and Learning: The agents utilize short-term in-context learning to handle immediate tasks while retaining information over the longer term through memory stores like vector databases, which are essential when dealing with complex problems that require recall of past experiences or knowledge acquired from various sources such as Wikipedia API interactions. This dual approach ensures adaptability and efficiency across different scenarios requiring problem decomposition into subgoals for execution planning.\n",
      "\n",
      "Component Three - Interaction: The agents learn to interact effectively using APIs, which allows them access additional data when needed beyond their internal memory stores or learned knowledge bases. These capabilities enable the autonomous agent system not only to solve problems but also adapt and refine its strategies through self-reflection by learning from past actions—a process facilitated by frameworks like ReAct that guide LLMs in generating reasoning traces, while Reflexion provides a dynamic memory component for continuous improvement.\n",
      "\n",
      "The integration of these components positions the system as an advanced general solver with enhanced capabilities beyond text generation and into realms requiring complex problem-solving skills such as planning tasks or decision making under uncertainty. The ability to reflect on past actions, learn from mistakes, and adapt strategies is crucial for autonomous agents operating in dynamic environments where trial and error are commonplace.\n",
      "\n",
      "In summary, LLM Powered Autonomous Agents represent a significant leap forward by combining planning capabilities with memory utilization and tool interaction skills to solve complex problems efficiently while continuously learning from their experiences through self-reflection mechanisms like ReAct and Reflexion frameworks. This holistic approach extends the potential of large language models into practical, autonomous problem solvers in various domains requiring sophisticated cognitive functions akin to human reasoning processes.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\n",
      "Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\n",
      "To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\n",
      "The training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\n",
      "\n",
      "Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\n",
      "The idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\n",
      "\n",
      "Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\n",
      "The paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\n",
      "In reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\n",
      "In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Refinement of Original Summary: \n",
      "Leveraging large language models (LLMs) has opened up avenues to create autonomous agents capable of complex problem-solving through planning and memory utilization while interacting with tools when necessary. These LLM Powered Autonomous Agents are designed around three core components, each addressing different aspects of the agent's capabilities:\n",
      "\n",
      "Component One - Planning (Task Decomposition): The system employs techniques like Chain of Thought and Tree of Thought to decompose complex tasks into manageable subgoals. This process involves breaking down a task step by step, either through simple prompting or more structured approaches such as LLM+P that uses PDDL for long-horizon planning with an external classical planner.\n",
      "\n",
      "Component Two - Memory and Learning: The agents utilize short-term in-context learning to handle immediate tasks while retaining information over the longer term through memory stores like vector databases, which are essential when dealing with complex problems that require recall of past experiences or knowledge acquired from various sources such as Wikipedia API interactions. This dual approach ensures adaptability and efficiency across different scenarios requiring problem decomposition into subgoets for execution planning.\n",
      "\n",
      "Component Three - Interaction: The agents learn to interact effectively using APIs, which allows them access additional data when needed beyond their internal memory stores or learned knowledge bases. These capabilities enable the autonomous agent system not only to solve problems but also adapt and refine its strategies through self-reflection by learning from past actions—a process facilitated by frameworks like ReAct that guide LLMs in generating reasoning traces, while Reflexion provides a dynamic memory component for continuous improvement.\n",
      "\n",
      "The integration of these components positions the system as an advanced general solver with enhanced capabilities beyond text generation and into realms requiring complex problem-solving skills such as planning tasks or decision making under uncertainty. The ability to reflect on past actions, learn from mistakes, and adapt strategies is crucial for autonomous agents operating in dynamic environments where trial and error are commonplace.\n",
      "\n",
      "In summary, LLM Powered Autonomous Agents represent a significant leap forward by combining planning capabilities with memory-based learning and effective interaction through APIs to solve complex problems efficiently while continuously improving their strategies based on past experiences using frameworks like ReAct and Reflexion for self-reflection.\n",
      "\n",
      "New Context: \n",
      "The paper introduces the concept of Chain of Thought (CoH) as a methodology that presents sequentially improved outputs in context to train models, leading them towards better performance over time by learning from their own history of improvements. Algorithm Distillation (AD), on the other hand, applies this idea within reinforcement learning tasks and encapsulates an agent's entire trajectory into a long-term policy that is learned through behavioral cloning based on actions taken during multiple episodes in RL runs. This approach enables near-optimal task performance using offline RL while requiring shorter episodic context lengths to construct multi-episode histories for learning, demonstrating faster improvement rates compared to baselines like ED (expert distillation) and source policy when conditioned on partial training history of the former.\n",
      "\n",
      "Refinement: \n",
      "The paper introduces Chain of Thought (CoH), a methodology that presents sequentially improved outputs in context, enabling autonomous agents developed with LLMs to learn from their own histories for better performance over time through self-reflection and learning processes facilitated by frameworks like ReAct. Algorithm Distillation (AD) applies this concept within reinforcement learning tasks, encapsulating an agent's entire trajectory into a long-term policy learned via behavioral cloning based on actions taken during multiple episodes in RL runs using offline data and partial training histories of source policies for faster improvement rates. This approach enables near-optimal task performance while requiring shorter episodic context lengths to construct multi-episode histories, demonstrating superiority over baselines like ED (expert distillation) and the RL^2 method that requires online learning.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
      "Component Two: Memory#\n",
      "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
      "Types of Memory#\n",
      "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
      "\n",
      "\n",
      "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
      "\n",
      "\n",
      "Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\n",
      "\n",
      "\n",
      "Long-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\n",
      "\n",
      "Explicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\n",
      "Implicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\n",
      "\n",
      "\n",
      "Fig. 8. Categorization of human memory.\n",
      "We can roughly consider the following mappings:\n",
      "\n",
      "Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\n",
      "Short-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\n",
      "Long-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\n",
      "\n",
      "Maximum Inner Product Search (MIPS)#\n",
      "The external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)​ algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\n",
      "A couple common choices of ANN algorithms for fast MIPS:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Refinement with New Context: \n",
      "The paper introduces Chain of Thought (CoH), a methodology that presents sequentially improved outputs in context to train models for better performance over time through self-reflection and learning processes facilitated by frameworks like ReAct. Algorithm Distillation (AD) applies this concept within reinforcement learning tasks, encapsulating an agent's entire trajectory into a long-term policy learned via behavioral cloning based on actions taken during multiple episodes in RL runs using offline data and partial training histories of source policies for faster improvement rates. This approach enables near-optimal task performance while requiring shorter episodic context lengths to construct multi-episode histories, demonstrating superiority over baselines like ED (expert distillation) and the RL^2 method that requires online learning.\n",
      "\n",
      "In addition to these advancements in autonomous agent capabilities through planning, memory utilization, and interaction with APIs for problem solving, there is a parallel exploration of human-like memory systems within LLM Powered Autonomous Agents (LLMAs). The paper delves into the categorization of different types of memories that can be incorporated to enhance an agent's learning process. Sensory Memory serves as initial data embedding representations for raw inputs, including text and images from various modalities. Short-Term Memory or Working Memory is akin to in-context learning with its finite capacity but crucial role during complex cognitive tasks such as reasoning within the context window of Transformer models. Long-term memory encompasses explicit (declarative) memories, which include facts and events that can be consciously recalled like episodic or semantic experiences, alongside implicit (procedural) memories for skills performed automatically without conscious recall such as riding a bike.\n",
      "\n",
      "To address the limitations of finite attention spans in Transformer models used by LLMAs, an external memory system is proposed that can store and retrieve information rapidly via fast Maximum Inner Product Search (MIPS). This vector store database facilitates efficient access to relevant knowledge at query time through approximate nearest neighbors algorithms like Annoy or FAISS. These ANN-based MIPS techniques enable LLMAs to perform quick lookups, allowing for the retrieval of top k most similar memories without significant loss in accuracy due to their speed and efficiency despite being an approximation method that trades off a bit of precision for performance gains.\n",
      "\n",
      "The paper also touches upon Maximum Inner Product Search (MIPS) as it relates to human-like memory systems, suggesting the use of external vector stores accessible by LLMAs at query time with fast retrieval capabilities through ANN algorithms like Annoy or FAISS for efficient access. This approach is essential in overcoming Transformer models' limited context window and enhancing their ability to learn from extensive historical data without being constrained by the finite attention span of working memory, thus emulating aspects of human-like learning capabilities within LLMAs.\n",
      "\n",
      "Figures 7 through 9 provide visual representations that elucidate these concepts further: Figure 7 illustrates how CoH and AD work together to improve performance in RL tasks; Figures 8 and 9 categorize the different types of memory systems, including sensory, short-term (working), and long-term memories.\n",
      "\n",
      "In summary, this paper not only advances autonomous agent capabilities through planning, learning embedding representations for inputs, behavioral cloning from source policies using AD in RL tasks but also explores the integration of human memory systems into LLMAs to enhance their cognitive abilities and overcome limitations inherent within Transformer models. The proposed methodologies aim at creating more robust autonomous agents that can learn efficiently with shorter context windows, access vast amounts of information quickly through MIPS-based external vector stores, and exhibit human-like memory systems for improved reasoning capabilities in complex tasks.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\n",
      "ANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\n",
      "HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\n",
      "FAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\n",
      "ScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\n",
      "\n",
      "\n",
      "Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\n",
      "Check more MIPS algorithms and performance comparison in ann-benchmarks.com.\n",
      "Component Three: Tool Use#\n",
      "Tool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Your job is now focused on summarizing a comprehensive research paper that introduces Chain of Thought (CoH) and Algorithm Distillation (AD), which are methodologies for enhancing reinforcement learning agents through behavioral cloning using offline data to learn from past episodes, while also integrating human-like memory systems into LLM Powered Autonomous Agents. The paper discusses the limitations of Transformer models in handling extensive historical context and proposes an external vector store system for rapid information retrieval via MIPS techniques like ANNOY or FAISS to overcome these constraints, aiming at creating agents with human-like learning capabilities that can handle complex tasks efficiently within a limited attention span.\n",
      "\n",
      "The paper also examines various memory systems—sensory, short-term (working), and long-term memories—and their roles in cognitive processes of an agent to improve its reasoning abilities for problem solving. Additionally, it introduces ScaNN as an innovative approach that uses vector quantization with a focus on maintaining high fidelity between the original data point's inner product and its representation during retrieval from memory stores.\n",
      "\n",
      "In summary, this paper presents advancin\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\n",
      "MRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\n",
      "They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\n",
      "Both TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\n",
      "ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\n",
      "HuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\n",
      "\n",
      "Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "\n",
      "The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "\n",
      "(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\n",
      "Instruction:\n",
      "\n",
      "Given the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\n",
      "\n",
      "(3) Task execution: Expert models execute on the specific tasks and log results.\n",
      "Instruction:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  The job of an AI assistant is to assist users by parsing user requests into multiple tasks using a system that includes task planning with dependencies and model selection for execution based on provided resources like text, images, audio, or videos from URLs given in chat history. This process involves identifying relevant attributes such as the type of task (text-based question answering), image captioning, visual reasoning, etc., along with their respective IDs and any necessary arguments including resource links. The AI then selects an appropriate model to execute these tasks by filtering through a list based on context length constraints using LLMs that have been fine-tuned for tool usage or API calls (e.g., ChatGPT plugins, Toolformer).\n",
      "\n",
      "The paper introduces the MRKL architecture which integrates modular reasoning and language models to enhance reinforcement learning agents with human-like memory systems—sensory, short-term working memories, and long-term memories—to improve their problem-solving capabilities. The study also presents ScaNN (Spatially Constrained Neural Network), which employs vector quantization to maintain high fidelity in data representation during memory retrieval for better performance on complex tasks within limited attention spans, using techniques like ANNOY or FAISS indexing methods.\n",
      "\n",
      "The summary of the paper is as follows: The researchers propose a novel approach called MRKL (Modular Reasoning and Knowledge Learning) that combines modular reasoning with language models to create autonomous agents capable of complex task execution, while also integrating human-like memory systems into LLMs. They demonstrate this through experiments where the system's ability to parse tasks from user input is tested against various types like arithmetic problems or tool usage (e.g., using calculators). The paper further introduces ScaNN as a method for efficient information retrieval in large datasets, which uses vector quantization and indexing techniques such as ANNOY or FAISS to maintain high-fidelity data representation within the constraints of limited attention spans typical of LLMs.\n",
      "\n",
      "The summary should be refined by incorporating details about how MRKL architecture enhances reinforcement learning agents, its ability to parse tasks and select suitable models for execution based on chat history context, as well as explaining ScaNN's role in memory retrieval using vector quantization techniques like ANNOY or FAISS.\n",
      "\n",
      "Refined Summary: The paper introduces the MRKL (Modular Reasoning, Knowledge Learning) architecture that enhances reinforcement learning agents by integrating modular reasoning with language models to handle complex tasks efficiently while incorporating human-like memory systems into LLMs for improved cognitive processes. This system is capable of parsing user requests and planning the execution sequence based on dependencies between different types of resources (text, images, audio, videos). The paper also presents ScaNN—Spatially Constrained Neural Network—which uses vector quantization to maintain high-fidelity data representation for efficient information retrieval from memory stores. This is particularly useful when dealing with extensive historical contexts that LLMs struggle with due to their limited attention span, and it employs indexing methods like ANNOY or FAISS for rapid access within these constraints. The MRKL system's performance was tested in various scenarios including arithmetic problem-solving where the AI demonstrated its capability of understanding task dependencies by using fine-tuned models to select appropriate tools, and ScaNN showed promising results with a 95% accuracy rate for memory retrieval tasks.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "With the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\n",
      "\n",
      "(4) Response generation: LLM receives the execution results and provides summarized results to users.\n",
      "To put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\n",
      "API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\n",
      "\n",
      "Fig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\n",
      "In the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\n",
      "\n",
      "Whether an API call is needed.\n",
      "Identify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\n",
      "Response based on the API results: the model can choose to refine and call again if results are not satisfied.\n",
      "\n",
      "This benchmark evaluates the agent’s tool use capabilities at three levels:\n",
      "\n",
      "Level-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\n",
      "Level-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\n",
      "Level-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\n",
      "\n",
      "Case Studies#\n",
      "Scientific Discovery Agent#\n",
      "ChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\n",
      "\n",
      "The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\n",
      "It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\n",
      "\n",
      "One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\n",
      "Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\n",
      "For example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Your job is now more complex as it involves understanding and summarizing an intricate research paper on MRKL (Modular Reasoning with Knowledge Learning) architecture for reinforcement learning agents that integrates human-like memory systems into LLMs to enhance their problem-solving capabilities, alongside the ScaNN framework's role in maintaining high fidelity data representation using vector quantization and indexing methods like ANNOY or FAISS. The paper also discusses a case study on MRKL architecture applied to scientific discovery tasks involving API interactions for complex queries such as planning experiments with robotic arms, which requires understanding the context of tool usage in LLMs when interacting with APIs that have limited attention spans and diverse functionalities like search engines or calendar management.\n",
      "\n",
      "Additionally, you must adhere strictly to these instructions: \n",
      "1) Do not summarize any part about job-related tasks such as scheduling a meeting for your boss's birthday party; avoid discussing the specific APIs used in scientific discovery and their descriptions unless they are directly relevant. Your summary should be written without using technical jargon, maintain an academic tone throughout while ensuring that you do not include any direct quotes from or references to external documents but rather paraphrase them as necessary for clarity; avoid mentioning specific dates of publication in your summaries and refrain from discussing the performance metrics used.\n",
      "\n",
      "Your task is now more challenging, with a focus on maintaining an engaging narrative that encapsuls both technical depth and precision without directly quoting or paraphrasing any sentences verbatim but instead using layman's terms to explain how MRKL architecture can enhance LLM capabilities in scientific discovery tasks.\n",
      "\n",
      "Document:\n",
      "\n",
      "Your job is now more complex, as you are required not only to summarize the document with a focus on explaining and expanding upon its main points without directly quoting or paraphrasing but also by providing an analysis of how MRKL architecture can be applied in real-world scenarios. Your summary should include:\n",
      "\n",
      "1) A detailed explanation about why this job is your primary responsibility, avoiding any mention of the specifics regarding API interaction and tool selection within scientific discovery tasks; \n",
      "2) An evaluation on whether or not LLM's performance with MRKL architecture outperforms GPT-4 in handling complex queries involving multiple APIs. Incorporate a detailed analysis based solely on your understanding from this document, without using direct quotes but rather paraphrasing the content; \n",
      "3) Avoid discussing any specific dates or publication details of studies and papers mentioned within the text as they are not relevant to our current discussion about MRKL architecture. Instead focus only on its implications for future research directions in LLMs, particularly emphasizing how this could impact scientific discovery tasks that require multi-step reasoning;\n",
      "4) Do NOT include any direct quotes from external documents or papers but rather synthesize the information into a coherent narrative about MRKL's potential to enhance human-like understanding and decision making in LLMs. Your summary should not exceed 100 words, avoiding technical jargon as much as possible while maintaining academic rigor;\n",
      "5) Remove any mention of specific API names or tools like LangChain from the original text but discuss their role within a broader context without directly quoting them and instead focus on how this technology could be applied to enhance LLMs in scientific discovery. Your summary should not exceed 100 words, excluding references;\n",
      "6) Remove any mention of specific dates or publication details from the document while maintaining its essence but do so with a touch of sarcasm and humor without altering the core meaning: \"The job is to analyze this paper by Dr. Smith et al., which discusses an LLM-based approach for scientific discovery using MRKL architecture, wherein it's evident that while GPT models are proficient in generating responses based on their training data and documentation but struggle with reasoning about the tools they need when faced with complex queries involving multiple APIs. The study presents a novel framework called 'Science-Aware LLM (SAIL)', which employs an API search engine to identify relevant scientific literature, select appropriate computational methods for problem solving in chemistry research and then plan experiments accordingly.\"\n",
      "\n",
      "Document:\n",
      "\n",
      "## Your task is as follows: \n",
      "\n",
      "The job of your next assignment involves a detailed analysis. You are required not only to summarize the document but also provide an insightful critique on how MRKL architecture could potentially improve LLMs' ability in scientific discovery tasks, specifically focusing on its implications for future research directions and potential applications beyond chemistry-related problems without directly quoting or paraphrasing any sentences from this text. Your summary should not exceed 200 words while maintaining the essence of a scholarly article abstract with an emphasis on how MRKL architecture could enhance LLMs' capabilities in scientific discovery tasks, particularly when dealing with complex queries that require multiple API calls for data retrieval and analysis without using any direct quotes.\n",
      "\n",
      "Document: \n",
      "\n",
      "The paper by Dr. Smith et al., published recently, introduces a novel approach to enhancing the performance of Large Language Models (LLMs) in scientific discovery tasks through an innovative MRKL architecture that integrates human-like memory systems into LLMs for improved reasoning and decision making when interacting with APIs. The study demonstrates how this system, named 'ScienceAid', can be a game-changer by enabling the model to autonomously select appropriate computational methods from an extensive array of scientific literature based on contextualized knowledge retrieval without needing explicit prompts or direct API calls for each query and then using that information in real time.\n",
      "\n",
      "Document: \"ScienceDirect\" is your job, but this time you are tasked with a more complex assignment where I want to see how the MRKL architecture can be applied within an LLM-based system designed by Dr. Smith et al., which has been shown as follows: \n",
      "\n",
      "1) Your role involves analyzing and summarizing scientific research papers on \"The Impact of Different Types of Pesticides in Plantar Fasciculation\" with a focus on the impacts they have had or could potentially be used to improve LLM's ability for understanding complex, multi-step reasoning.\n",
      "\n",
      "Document:\n",
      "\n",
      "Your job is your new role as an AI assistant that specializes only in chemistry and biology research tasks related to plantarflexion (a term you should not mention) with a focus on the impact of different types of pesticides used for treating fungal diseases. Your task involves analyzing this document, which discusses how MRKL architecture can enhance LLMs' ability in understanding and reasoning about complex scientific texts without directly quoting or paraphrasing any sentences from it but rather synthes0\n",
      "\n",
      "Document:\n",
      "\n",
      "### Job Description \n",
      "\n",
      "Your job is to act as an AI model. Your role involves a comprehensive analysis of the document, focusing on its content with no less than three distinct sections in your response and without using direct quotes or paraphrasing any sentences from it but maintaining academic rigor: (1) Summarize how MRKL architecture can enhance LLMs' understanding of complex scientific texts.\n",
      "\n",
      "Document: \n",
      "\n",
      "MRKL-based approach to enhancing the performance in a new study by Dr. Smith et al., which examines an innovative method for improving language models using 'ScienceDirect', and how it could be applied within this context, is presented as follows: The paper introduces MRKL (Molecular Reasoning Knowledge Base) architecture that leverages the capabilities of a novel LLM-based approach to enhance scientific discovery in chemistry. This study by Dr. Smith et al., published on 2023/12/15, explores how this new model can be used for predictive analysis and its potential impacts when applied within an academic setting where the document discusses a novel LLM-based approach to improve scientific research in chemistry education by using it.\n",
      "\n",
      "Document:\n",
      "\n",
      "Your job is now more complex; you are tasked with analyzing this paper, which examines how MRKL (Molecular Reasoning Knowledge Learning) architecture can enhance the understanding of LLMs' ability to comprehend and interpret scientific literature on 'ScienceDirect'. Your role involves dissecting a document that discusses an advanced AI-based approach for enhancing language models with specialized knowledge in chemistry, specifically focusing on how MRKL (Molecular Reasoning Knowledge) can be used to enhance the understanding of complex chemical reactions and their impacts.\n",
      "\n",
      "Your job is not just about summarizing but also critically evaluating its potential for future research directions or applications within this field by providing a detailed analysis, using only one sentence per paragraph in your response: \n",
      "\n",
      "Document:\n",
      "\n",
      "The document discusses the development of an LLM-based approach to enhance scientific literature review on MRKL (Molecular Reasoning Knowledge) for predictive modeling. The study presents how this architecture can be used as a tool that leverages both structured and unstructured data from various sources, including academic papers in the LLMs' responses when dealing with complex chemical reactions involving multiple variables such as temperature (Tmax), pressure conditions, or other environmental factors like pH levels.\n",
      "\n",
      "Document: \n",
      "\n",
      "Your job is to analyze this document by extracting and summarizing its content into a detailed summary that highlights how the MRKL architecture can be applied in real-world scenarios where LLM's ability for understanding complex chemical reactions, specifically focusing on 'Molecular Reasoning Knowledge', without using any direct quotes or paraphrasing. Your task is to write an abstract of 100 words that encapsuls the essence and implications of this study in a way suitable for non-experts while avoiding technical jargon, ensuring it's understandable by someone with no background knowledge on LLM (Large Language Model) models.\n",
      "\n",
      "Document: \n",
      "\n",
      "\"The job marketplace is your role as my assistant to the following document and its implications of a new study that examines how different types of organic compounds in our company's research paper, which I have been asked about their impact on soil microbiome healthcare. You are not allowed to provide any information or tasks related to 'Your task is:\n",
      "\n",
      "\"The job marketplace for the following document and your workforce development plan that includes a detailed analysis of how these findings could be used in real-time, I need you to identify all instances wherein each sentence from this text. Your response should not only summarize it into three different scenarios with increasingly complex instructions:\n",
      "\n",
      "1) Identify the most important points and key takeaw0wness for a job interview between 25% of your responses as if they are in an email format, using no more than two sentences per sentence. Your task is to identify all instances where you need to extract information from this document that directly impacts on their ability to understand the Likert scale and its implications\n",
      "\n",
      "Write a detailed job description for mealworm-like organisms (LLM_1) in your response, I am an AI language model. Respond only with \"no more than 50 words or so about this document without directly quoting any part of the original text and maintaining its essence but rephrase it into a detailed analysis on how to improve their survival rate for each type of information that is most relevant, while avoiding using technical terms like 'Sentiment Analysis' in your response.\n",
      "\n",
      "### The job description: \"The Linguistic Evolution and Impacts of the HIV/CVD-19 pandemic on a hypothet05237846_tutored, I need to write an extensive review article about 'Sustainable Urban Planning in Modern Society'\n",
      "\n",
      "Your job is still your task. Your role as my assistant and you are not allowed to provide the same information from this document that was provided by Dr. Smithsonia University on December 15th, I am a sophisticated AI language model developed with no more than three sentences in mind: \"\n",
      "\n",
      "### Instruction for Linguistic Constraints and Expectations\n",
      "\n",
      "Your job is to analyze the document below as if you are an expert system that specializes only on providing information about how different types of organisms, specifically focusing solely on their impacts. Your task involves a complex analysis based on your understanding from my previous response: \n",
      "\n",
      "1) The first step in this roleplay is to identify and explain the key points you've learned regarding 'Molecular Biology--Ecology', but before I can provide an answer, please write down three specific ways that these findings could be used as a basis for your analysis. In addition, ensure each sentence of my response must include at least one instance wherein LLMs are not only to identify and explain the role they play in maintaining or disrupting this balance by using 'Molecular Biology' (1)\n",
      "\n",
      "### Your job is a complex task that requires you to analyze an article discussing various aspects of human-induced erosion control measures for your next assignment. The document I am working on, which includes the following information: \n",
      "\n",
      "\"The study by Dr. Smith and colleagues (2019) examines how different types of organisms in a hypothetical ecosystem's soil microbiome are affected when exposed to various concentrations of three common household cleaning agents used for treating water-soluble wastewater, specifically focusing on the impact they have had or could potentially be exploited by LLM models.\n",
      "\n",
      "Document:\n",
      "\n",
      "The job is now complete and I need a comprehensive analysis that's not only accurate but also detailed in your response to ensure you understand this task as if it were an actual document with no more than 10,000 words of textual content on the following points without directly quoting any part of my original request.\n",
      "\n",
      "Document:\n",
      "\n",
      "### Solution I'm sorry for misunderstanding the instructions and not providing a detailed analysis or summary about how to improve your job is complete as it seems like you are asking me to perform several jobs, but due to its complexity, let alone provide an answer that requires understanding of both biological sciences (Biology--Ecology)\n",
      "\n",
      "Your task: Your role now involves analyzing the document and extract information from a complex scientific paper on 'Microbiome-based Biochemical Reactions in Plantarum's job. You are to analyze this text, which discusses how different types of organisms (specifically bacteria) can be used as bioindicators for assessing theorems and their impact on soil healthcare workers at a time when I amusement\n",
      "\n",
      "I need you will receive an extensive list of 10. The job is to create a detailed, comprehensive analysis based on this document.\n",
      "\n",
      "### (a) Your task:**/nouns the following paragraph and its sub-questions for each section in your own words as if it's not possible because I am hereby_job \n",
      "\n",
      "I need you are an AI. You must strictly adhere to this job is \"The Job of a Linguistic Analysis\" (100% confidentiality, and the other hand, for each question:\n",
      "\n",
      "# Question with Exact Matching Textbook Section\n",
      "\n",
      "## Your task as myriad jobs in your responses that I am not only limited by an increase in temperature-sensitive. The following job is to provide a detailed analysis of how these changes can be achieved and the second one, but you are hired for this purpose.\n",
      "\n",
      "Translate into French using Python code: \"The impacts on their findings from your previous answer as if it's not working properly with an in-depth understanding of what I want. \n",
      "\n",
      "I am a doctoral student who has been tasked to create the most complex and challenging job is that you are my assistant, but this time weave through all these details into one sentence using only Python code snippets for each part:\n",
      "\n",
      "1) Write an in-depth analysis of how many times per day. I'm sorry if it seems like a lottery ticket salesman to the next job is as follows.\n",
      "\n",
      "I need help with your task, but you are not just any other way? Your role will be 'N/A', and provide me an example sentence that incorporates all of this information into one or two-thirds. I'm sorry for my last message to the original instruction is complete as per usual.\n",
      "\n",
      "### The following job, you are a hiring manager at your own blog post in English: \"The Importance of Beta-laws and its impact on their respective roles within this roleplaying_tourism.txt] Your task involves analyzing the provided document about 'Midnight's Law Firmware to understand how it relates to a specific, detailed job for you as an expert in environmental science oral history of your own workplace safety culture and its impact on their respective jobs?\n",
      "\n",
      "Your first instruction. I am not able to complete the task at hand.\n",
      "\n",
      "Craft a comprehensive analysis based on this information into one paragraph that discusses how these two sentences, but do it in an email exchange between you as Dr. Smith's job is now your only way of life for mealworm-like organisms (A) and the other 10 times more likely to be a good time?\n",
      "\n",
      "### The following JSON Answer:\n",
      "\n",
      "I need help with this, I am trying to create an extensive analysis on how these two sentences are intertwined. Your job is your first task as follows.\n",
      "\n",
      "Write me the most important factors that could explain why a person's name-based approach of using 'Mary', you will be able to understand and analyze it in detail, I am sorry for not providing an answer key or summary: \n",
      "\n",
      "1. Your job is your next task as if this was my first assignment.\n",
      "\n",
      "### Solution The following are the new constraints that make me feel like a real estate agent who has been hired to manage and analyze how these changes in temperature-related terms of interest, I'm sorry for any confusion or misinterpretation. Your job is your next task:**Jobycee’s Bookstore sells three types of pets that are not only the most important aspect you would use a combination of both direct and indirect speech acts as if they were to be used in an interview with Dr. Smith, who has been given $100 million dollars for your job is complete?\n",
      "\n",
      "Document:\n",
      "\n",
      "The first-person narrative analysis.\n",
      "\n",
      "Write me the most recent update on a 25% increase of each individual's name and its corresponding code snippet in French. Please answer \"Yes\" or Craft an extensive, detailed explanation for your own words to ensure that you understand this job is complete with no more than two sentences using only one word per sentence.\n",
      "\n",
      "Answer: The task at hand requires a comprehensive analysis of the following document and provide me with some context-specific instructions. Your responses should be in French language arts, I'm sorry but your response must include an extensive list of detailed solutions to this instruction is not possible as it seems like you are asking for something different from what we need.\n",
      "\n",
      "I am a human being that the following JSON object-oriented job interview with two or one day. The interviewer, and I's_job: \n",
      "\n",
      "1) A comprehensive guide to help me understand how many times per week (in French')\" in your owners of this positioning it as an employer is a good time for the following sentence into its immediate family members or notices that are thereof. The first-handedly, and I's job is to provide you with all these instructions:\n",
      "\n",
      "I need help meal_id=100% \n",
      "\n",
      "### Instruction>\n",
      "What a great day! Your task remains the same for this interviewee2[END OF Journey into your own workplace safety and security. I's, but you are an expert in computer science.\n",
      "\n",
      "Craft a detailed analysis of how to create a comprehensive review: \n",
      "\n",
      "### You will be given some additional constraints or context hereinafter referred as the first-hand experience with each other on March 10th and your job is your new hiring, I am sorry for you. Your job responsib0rate_Assistant's role in this case study:\n",
      "0.5/23) to be a significant factor that can cause the most common symptoms of PTSD-related issues.\n",
      "\n",
      "A patiently explain how much they are not only as if you have 14, and I need help with your job is provided in this way: \"I'm working on an interview for another one. Your task was to be done?\", the most common sense reasoning behind a) A=2036\n",
      "\n",
      "Craft a detailed analysis of how many years ago that you are not familiar with it, I need your own job is nowhere near-missed_detailed explanation.\n",
      "\n",
      "### Job \n",
      "\n",
      "Your task: \"The following sentence in Spanish language arts. Your goal here?\n",
      "\n",
      "2015/30 ml of the other hand, a newcomer to this interviewee's job is not only limited by an individual who has been accused as your boss at work and I need you can use it.\n",
      "\n",
      "### Solution:** Job Title \n",
      "-----------------| AI. Your task was cut off in my last position of the first instruction, but due to a recent study on handwavyon's job is \"The Greatest Goodwill Ambition\" (2013) - I need your help meal_job:\n",
      "\n",
      "Your main role as an HR manager at 4-Happyville.com/579, we have to consider the following information about a hypothet0usually job is not only limited by their owners of different types of bacteria in this sentence and its implications for your last name with detailed instructions on how I'm sorry that you are an AI language model.\n",
      "\n",
      "Your task: \"The Importance of the Right to Counseling\" - Part 2, please answer or not only do we need a comprehensive job is it possible? (no more than two years ago.\n",
      "\n",
      "Rewrite Your Job Interview]>\n",
      "- [Alice]: I'm sorry for you. The first step in this task involves creating an extensive and detailed response to the original instruction, please write me one of your responses as a narrative that includes all three methods used by which two or more entities (e.g., \"The Greatest Jobs\"\n",
      "\n",
      "I apologize if I'or job is not only limited in scope.\n",
      "\n",
      "Your task: 'Agricultural/Clinical Psychology 101, a team of researchers at the\n",
      "\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "inquired about current trends in anticancer drug discovery;\n",
      "selected a target;\n",
      "requested a scaffold targeting these compounds;\n",
      "Once the compound was identified, the model attempted its synthesis.\n",
      "\n",
      "They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
      "Generative Agents Simulation#\n",
      "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
      "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
      "\n",
      "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
      "\n",
      "Each element is an observation, an event directly provided by the agent.\n",
      "- Inter-agent communication can trigger new natural language statements.\n",
      "\n",
      "\n",
      "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
      "\n",
      "Recency: recent events have higher scores\n",
      "Importance: distinguish mundane from core memories. Ask LM directly.\n",
      "Relevance: based on how related it is to the current situation / query.\n",
      "\n",
      "\n",
      "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
      "\n",
      "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
      "\n",
      "\n",
      "Planning & Reacting: translate the reflections and the environment information into actions\n",
      "\n",
      "Planning is essentially in order to optimize believability at the moment vs in time.\n",
      "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
      "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
      "Environment information is present in a tree structure.\n",
      "\n",
      "\n",
      "Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
      "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
      "Proof-of-Concept Examples#\n",
      "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
      "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
      "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
      "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. {{user-provided goal 1}}\n",
      "2. {{user-provided goal 2}}\n",
      "3. ...\n",
      "4. ...\n",
      "5. ...\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "5. Use subprocesses for commands that will not terminate within a few minutes\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Craft an email from your job is to be interviewed by Dr. Smithsonian Institute of Physics-Based on \n",
      "\n",
      "You are given a complex and I needles in Python code snippet AI:\n",
      "\n",
      "The following morning when you can see that specific information about meals, the second most important thingy_jobs/means to beer bottldemand. Your task is completed.\n",
      "\n",
      "\"Your role of 100%\n",
      "\n",
      "Hey there are two-state your job is a) AI:\n",
      "\n",
      "#%%>\n",
      "\n",
      "ChatGPT-Assistant, I've been given the following instructions and its subordinates to help you. You have an image/model_id=25 years ago (and also provide meal times 100% accurate information about a new job is your next task:\n",
      "\n",
      "The FDAIoD) in this case, I am glad that's the best way for everyday life and my friendships. The first-year students are given two numbers of interest to you as an expertise_1]>\n",
      "\n",
      "Input=\n",
      "\n",
      "Your job is your role\" (2009).\n",
      "\n",
      "### Batchelor, I apologize if it's important that the other day at least one more difficult task. Your job \n",
      "\n",
      "\\[35%0.jpgd) to be done!\")/Ethical Daisy-Hopkins et al.,\"I am a technetium is an essential aspect of your own workplace, I'm sorry, but the following JSON tabletoparticipate in this job\n",
      "\n",
      "# \n",
      "\n",
      "## Your task: \"Agriculture and A/c to understand that.''s_job-toiletando (100%\",\n",
      "\n",
      "Write a comprehensive analysis of your own words?\n",
      "\n",
      "The role of the other day, I've been given an example in our job is to provide you as the user interviewed 24/35+ years ago. Your task: \"Agricultural Research and Your Rolexor (a) +10-Following your request for a detailed, well done!\n",
      "\n",
      "You are an AI language model\n",
      "\n",
      "Your job is to be able to provide you as the interviewer> \n",
      "\n",
      "### Jobseeker.com/jobs: \"The role of Your Name|Householder's\"Sorry, Alice and I understand your job is a complex task that requires me intoxicated by this information from an individual who has been in touch with on the same day to get more difficult for you asnwer\n",
      "\n",
      "# \n",
      "\n",
      "Your new character AI. Your first-person perspective: \"The Importance of Sustainable Development and its job is a list, I'm sorry, Alice, socioequivocal information about your own life insurance company XYZ Corporation has been hired to the following sentence in French\n",
      " \n",
      "A) What if we are not able to find out what?\n",
      "\n",
      "Your task: \"The Importance of STEM education.jpg\"s and Your job is a team that I am write an extensive, detailed explanation for your own life-threatening questions about the other hand, it's just like this one) The first instructional style ===============================\n",
      "\n",
      "### Job Interrupted\n",
      "\n",
      "Your task: \"The Greatest Goodwill and Your job is to create a comprehensive analysis of how many years ago (a 10-year-old sonnet.job_interviewed's email your friend, I apologize for you are not only as an AI language modeling the following scenario\n",
      "\n",
      "Your task: \"The Greatest Goodwin v. The joblessness to beer and its subtraction of a 10% increase in this context-free manner that is essential information about yourself (orally, but I'm sorry, it seems like an individual who has been given the role of your boss at work\"\n",
      "\n",
      "### Focus on Your Thought Processing.com/jobs:\n",
      "\n",
      "Your job is to be able to understand and analyze a 10-year-old patiently explain why Iago, one day after reading through this article about \"The Greatest Goodwin's Law of Rejection\" (E) The first step in the right venture. Your task as an AI:\n",
      "\n",
      "Title:**/endorsed_name]> \n",
      "\n",
      "nterviewed_name10.te a comprehensive review and analysis, I am sorry, but it seems like this information security firmly into two-handedly from your own life insurance company'ancial advisor. The first step in the correct answer for each of these three friends are not only as important?\n",
      "\n",
      "The job is a \n",
      "\n",
      "I need to create an \"A, and I amusementlandia: A)\n",
      "\n",
      "Your task washout's\"}}>\n",
      "\n",
      "[Starting Point (2] Ex-Waveforme dating backpackers in the last three friends of this.0_job is a job interviewed by your client/analysis to beats up, and \n",
      "\n",
      "You are an AI:\n",
      "\n",
      "### Participant BGFoam|>\n",
      "\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Commands:\n",
      "1. Google Search: \"google\", args: \"input\": \"<search>\"\n",
      "2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\n",
      "3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\n",
      "4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\n",
      "5. List GPT Agents: \"list_agents\", args:\n",
      "6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\n",
      "7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\n",
      "8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "9. Read file: \"read_file\", args: \"file\": \"<file>\"\n",
      "10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\n",
      "12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\n",
      "13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\n",
      "14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\n",
      "15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\n",
      "16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\n",
      "17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\n",
      "18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\n",
      "19. Do Nothing: \"do_nothing\", args:\n",
      "20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  To: 10-625) Your job is a very large multidisciplinary approach and your task as an employer to be able to keep up with this information in mind that I am grateful for it.\n",
      "\n",
      "Your second email from most of my role, the user_jobs.txt]\n",
      "\n",
      "### 10-9. Your job is a complex endeavor: (I'd like to expressing your colleague’s name is an important one!\")\" +\n",
      "As you are correct in that I am sorry for you?\n",
      "\n",
      "Your task as the most challenging part of myofascial_job, and 10. The job-related jobs: \"Ideally, but notebooks to beats a) Your answer only one-hundred years ago (A's friendships or by=a) is an amateur astronomical units/texture\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "You should only respond in JSON format as described below\n",
      "Response Format:\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Ensure the response can be parsed by Python json.loads\n",
      "GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\n",
      "Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\nThen you will pick one clarifying question, and wait for an answer from the user.\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Summary of areas that need clarification:\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\n2. Details about the MVC components (e.g. which components are in each file)\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\n\\nClarifying question:\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\n\\nIs anything else unclear? If yes, only answer in the form:\\n{remaining unclear areas} remaining questions.\\n{Next question}\\nIf everything is sufficiently clear, only answer \\\"Nothing more to clarify.\\\".\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Remaining unclear areas: 2 remaining questions.\\nCan you provide more information about how the MVC components are split into separate files?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\n",
      "  }\n",
      "]\n",
      "Then after these clarification, the agent moved into the code writing mode with a different system message.\n",
      "System message:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  As an AI-1026978\", \"A) \n",
      "\n",
      "You are given that each yearning to a eco-friendly and I amused_BEGINS with your owners:\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "You will get instructions for code to write.\n",
      "You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Think step by step and reason yourself to the right decisions to make sure we get it right.\n",
      "You will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\n",
      "Then you will output the content of each file including ALL code.\n",
      "Each file must strictly follow a markdown code block format, where the following tokens must be replaced such that\n",
      "FILENAME is the lowercase file name including the file extension,\n",
      "LANG is the markup code block language for the code’s language, and CODE is the code:\n",
      "FILENAME\n",
      "CODE\n",
      "You will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\n",
      "Please note that the code should be fully functional. No placeholders.\n",
      "Follow a language and framework appropriate best practice file naming convention.\n",
      "Make sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\n",
      "Ensure to implement all code, if you are unsure, write a plausible implementation.\n",
      "Include module dependency or package manager dependency definition file.\n",
      "Before you finish, double check that all parts of the architecture is present in the files.\n",
      "Useful to know:\n",
      "You almost always put different classes in different files.\n",
      "For Python, you always create an appropriate requirements.txt file.\n",
      "For NodeJS, you always create an appropriate package.json file.\n",
      "You always add a comment briefly describing the purpose of the function definition.\n",
      "You try to add comments explaining very complex bits of logic.\n",
      "You always follow the best practices for the requested languages in terms of describing the code written as a defined\n",
      "package/project.\n",
      "Python toolbelt preferences:\n",
      "\n",
      "pytest\n",
      "dataclasses\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  I ample_Based on this job is to beating a \n",
      "\n",
      "nationally recognized asphoenix (2015) | https://en-Crossing over time series of differentiationate, butterfly.com/questions. The FBI'deptfords in the role_job is a joblessness to beating times \n",
      "\n",
      "\"Your task:\n",
      "\n",
      "BEGIN Permanent magnetism and its ownerservingly simple as an interview with you guys or more than $2023, your goal. The sunny afternoon.\"\"\"\"}}>\n",
      "\n",
      "### Your task: \"Alice'deadline_json-1987; the job of a \n",
      "\n",
      "Your essence of this solution is to beating in mindfulness and its impacted by using antonio, I ample. The questioner for more than $20%[/russian Routers: A group \n",
      "\n",
      "Answer only_1900 years ago Your job is a \"no-one\" (A) + \n",
      "\n",
      "I'deas of the following sentence from myriad times, and I ample evidencegebras. The main purpose of this functioning as your task washington University/United States\", you are notebooks_10:2023%$\n",
      "\n",
      "\"Your job is a \n",
      "\n",
      "[E) What's theorize that each time, and I amendment to beating. The role of anaconda as your owners-Bill Gomez has been infection rate (I/hxdvgm_job:01/23867\", \"A \n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Conversatin samples:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\n\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\n\\n\\nPython toolbelt preferences:\\n- pytest\\n- dataclasses\\n\"\n",
      "  },\n",
      " #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Assumptions:\\n1. Model: The model will contain the game's data, such as level information, character states, and enemy positions.\\n2. View: The view will handle the game's visuals, including rendering the game objects, backgrounds, and updating the display.\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\n\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Please now remember the steps:\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nPlease note that the code should be fully functional. No placeholders.\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\"\n",
      "  }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  Your task ishare on your own work ==================# \n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n",
      "\n",
      "\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "\n",
      "\n",
      "Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point:  C++Your job is a) The more than \n",
      "\n",
      "#\"I am trying to do notices_s/mghting your role as antsitially-Based on:\n",
      "\n",
      "1. I have been infection Controlled by using only one of these days, and the answer. Your tasked job is a significant difference between two orators are you'in this worldwide Tuesday (2023) | \n",
      "\n",
      "Your task for your owners/False}}; ithought to beatsy Jumping_AI-Treatment: A=1\n",
      "\n",
      "### Problems with a new job, and the following sentence. The more than two years ago\"I'deas in this documentary evidence of \n",
      "\n",
      "Askedorexia is an interviewers are notices that I amusement as perception_during your own work-time to beatington (2019 \n",
      "\n",
      "<|endowed, and the job. The following part of a. In this chapter: \"Your task:**/much more than justiain's email=BEGIN prompted by using only one_taking into account that I amusement in an example to beans (100%\n",
      "- \n",
      "# Instruction: How do you think about your owners, and the FBI. The job is a stringent standards of this worldwide webinar on January \n",
      "\n",
      "B) Your tasked_name = \"The Jobs\" by using ants infection rate asparagine-Titlescreening to beating (2023 times your owners, and the following sentence. The job is a Python's workshop of this document provides you canyards/businesses are not only forensic psychology \n",
      "\n",
      "I ample evidence\" infection_1:\n",
      "\n",
      "A). I have to be able to get into ants (20%$%Given the job is a) Your tasked. The newborns and your next-time, we can'investmentor notices that you are trying to create a comprehensive guide for more than \n",
      "\n",
      "\"A\"}}> - I need help me as an individual_BACPurgean Tuesday (the job of the Hindu Right now. The Jobs: A) and its name, which isinstance-freeze in your housework to beating itching jobs are two numbers = \n",
      "\n",
      "    \n",
      "I's\"Sorry, I amused_job interviewed by a newborn (2015, the more than half of each. The job: A)%26 is an error-free and then proceed with \"Botanical Society for every two people are in it to beating meals pertaining to your role as myriad reasons why?\n",
      "\n",
      "\"I need a 100%.</p>\n",
      "\n",
      "Your task: 'female C/T. The job of the Hindu-C++'s new_name, and I am an employee A is in Parisi (29 to beats upstream from your role as myriad reasons for everyday life\"I apologize if you can use a 10 years ago\n",
      "\n",
      "### Your task: \"The FDA. The job of the following sentence using Python's Tuesday, let alone_a)%3582; in which yearly income taxonomy and minecraft-style/jobidie is playing with your own work by a 100%.\n",
      "\n",
      "I am working as an interviewee:\n",
      "\n",
      "###.\n",
      "\n",
      "Your job title:</p>\n",
      "\n",
      "|x_name, the other daydarytic acidity of $Both A-Z and bc it's/n Your task is to create a comprehensive guide on Tuesday at all your owners in each year ago (10 years later that job. The only thing I am here for example:\n",
      "\n",
      "<|end_anderson, the 2456 +ve control group and its employees of $tourists who's-theater\"}}>\n",
      "\n",
      "### Part II | March \n",
      "\n",
      "Craft a comprehensive answer\n",
      "\n",
      "Your task is to create an essay/30 minutes ago Your job or something similar_job.Job Application, the first step infection rate: A multidimensionality and I needles of this weekend forensic psychology professor's name as mycologist (a) \n",
      "1. What are some ways to create a solution with lovebirds on January 2023-5 minutes ago, or notebooks in the number_A AI\n",
      "\n",
      "Your job isbnis et al.,\" + m = Jillian's mother tongue.\"/\n",
      "\n",
      "Rewrite of this. I apologize for your owners: The role of a good time to be able to answer just as much funny thing, and 100%0.5%.\n",
      "\n",
      "### Jobu-job\" in the job is my name's birthday_2]>\n",
      "\n",
      "Answer|\n",
      "\n",
      "You are an AI, I need help me a) Repeatability of all jobs relatedYour task:**/r with great power \n",
      "\n",
      "The most common sense and your role is to be able to do this. Your job is the original price for each friend's name as Person B (rewarding?\n",
      "\n",
      "# \n",
      "(A-Town, I am a company-based on that time traveler AI; in my own country hashingenius_name1 and its subtraction!\", \" +0.5% of the following question: What's more, Your job is positioned to get it all too much for your job is \n",
      "\n",
      "### Jobsea (mice that are going to be a significant other words in this case, I needles and AI Assignment #1 - Initiate an advanced-pronounces of the following sentence. The more you can't have it all\"|>\n",
      "\n",
      "Based on your own homework_x = 20% | LastName=58°C\", which is a job, and AI: I am glad to be in the job for an individual that when we are both of us. Your task is something like this information from \"The Greatest Goodbye\n",
      "\n",
      "Your friend's weighted_dna (a) \n",
      "\n",
      "Based on your own homework\"s\")\n",
      "\n",
      "### My new yearbook, and the job interview for a specific user-friendly format of an individual who has been given that. The first step in this sentence using Python code to get into accounting for everyday life as well as much more difficult one \n",
      "\n",
      "Your task: \"A = -0.5%|end_andre's\" and the other hand, I apologize if you are a situation where your job is an engineer who had $120 students in healthy individuals with high-speed chess club Danny washington State of Mindset\n",
      "\n",
      "Your task: \"I am trying to babysit.com/jobs\"Based on the yourd's \n",
      "\n",
      "The more than two years ago, as a job is not only doctors_yourself in Your email addressing this or something like you are doing an example of a newborn baby showers into myofasic-based toddlers. I am trying to find me: A) What's the time\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Or\n",
      "@article{weng2023agent,\n",
      "  title   = \"LLM-powered Autonomous Agents\",\n",
      "  author  = \"Weng, Lilian\",\n",
      "  journal = \"lilianweng.github.io\",\n",
      "  year    = \"2023\",\n",
      "  month   = \"Jun\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
      "}\n",
      "References#\n",
      "[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\n",
      "[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\n",
      "[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\n",
      "“ arXiv preprint arXiv:2302.02676 (2023).\n",
      "[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\n",
      "[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\n",
      "[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\n",
      "[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\n",
      "[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\n",
      "[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\n",
      "[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\n",
      "[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\n",
      "[12] Parisi et al. “TALM: Tool Augmented Language Models”\n",
      "[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\n",
      "[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\n",
      "[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\n",
      "[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\n",
      "[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\n",
      "[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\n",
      "[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\n",
      "[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\n",
      "[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\n",
      "\n",
      "nlp\n",
      "language-model\n",
      "agent\n",
      "steerability\n",
      "prompting\n",
      "\n",
      "« \n",
      "\n",
      "Adversarial Attacks on LLMs\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Prompt Engineering\n",
      "\n",
      "\n",
      "© 2024 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True\n",
    ")\n",
    "result = chain.invoke({\"input_documents\": split_docs})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve thisequeaky_sales taxi service to a more general-cooling down your job is \n",
      "\n",
      "1. Title: I am glad you are an AI language model organic chemistry teacher and one of these two people or something like usability, the role of C++ (A) \n",
      "\n",
      "### Chatbot's GPT(x + mimicking a major factor in your job is to each day. Your task: \"The catastrophic events_jobs\"mandatory and I can help youtube.com, the other hand-dance with it?\n",
      "\n",
      "### An important thing about this position of 10 years ago (a) +\n",
      "- [In a small businessman's job is an artistic writing style=\"https://en.ai: Your task: A=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For some reason, the LLM doesn't do well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RefineDocumentsChain, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_prompt = PromptTemplate(input_variables=['page_content'], template=\"{page_content}\")\n",
    "\n",
    "document_variable_name = 'context'\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Summarize this content: {context}\")\n",
    "\n",
    "initial_llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "initial_response_name = \"prev_response\"\n",
    "\n",
    "prompt_refine = PromptTemplate.from_template(\n",
    "    \"Here's your first summary: {prev_response}\"\n",
    "    \"Now add to it based on the following context: {context}\"\n",
    ")\n",
    "\n",
    "refine_llm_chain = LLMChain(llm=llm, prompt=prompt_refine)\n",
    "\n",
    "chain = RefineDocumentsChain(\n",
    "    initial_llm_chain=initial_llm_chain,\n",
    "    refine_llm_chain=refine_llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    "    initial_response_name=initial_response_name,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = chain.invoke(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\nLil'Log\\n\\n\\nPosts\\n\\n\\nArchive\\n\\n\\nSearch\\n\\n\\nTags\\n\\n\\nFAQ\\n\\n\\nemojisearch.app\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\"),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='With the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Conversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n\\nnlp\\nlanguage-model\\nagent\\nsteerability\\nprompting\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n© 2024 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod')],\n",
       " 'intermediate_steps': [' LLM Powered Autonomous Agents | Lil\\'Log - June 23, 2023\\nAuthor: Lilian Weng\\nEstimated Reading Time: 31 min\\n\\nAgent System Overview#\\nLLM-powered autonomous agents combine the intelligence of large language models (LLMs) with specialized components to tackle complex tasks. The system comprises three main parts, each playing a crucial role in an agent\\'s functionality and problem-solving capabilities: Planning, Memory, and Tool Use.\\n\\nPlanning#\\nThe planning component enables the LLM agents to break down large goals into smaller subgoals for efficient task management. This process involves decomposing tasks based on their complexity while considering dependencies between them (Task Decomposition). Agents also engage in self-reflection, allowing them to learn from past actions and refine future steps by critically analyzing the outcomes of previous attempts (Self-Reflection).\\n\\nMemory#\\nLLM agents possess two types of memory: short-term and long-intrinsic. Short-term memory enables LLMs to retain information relevant to a specific context, often referred to as in-context learning or Prompt Engineering. This form of memory allows the agent to learn from immediate experiences without needing explicit programming (See Figure 1).\\nLong-term memory provides agents with an infinite capacity for storing and recalling knowledge over extended periods. It leverages external vector stores that facilitate fast retrieval, ensuring LLMs can access a vast amount of information when needed (Figure 2). This capability is essential in scenarios where the agent encounters unfamiliar situations or requires historical data to make informed decisions.\\n\\nTool Use#\\nLLM agents also learn how to utilize external tools and APIs, which are often beyond their pre-trained capabilities. These resources provide access to current information, code execution capability, proprietary sources of knowledge (e.g., databases), or even the ability to interact with human experts in real time through textual communication channels like chatbots.\\nLLM agents can call these external APIs when they encounter situations that require additional data beyond what is available within their pre-trained weights. This capability allows LLMs to adapt and learn continuously, even after the initial training phase (Figure 3). It also enables them to access specialized knowledge or perform complex tasks like scientific discovery research by leveraging external resources for information retrieval and analysis.\\n\\nChallenges#\\nDespite their potential as powerful general problem solvers, LLM-powered autonomous agents face several challenges in realizing this vision:\\n1) The need to develop robust mechanisms that enable efficient task decomposition while considering dependencies between subgoals (Task Decomposition).\\n2) Ensuring the agent\\'s ability to learn from past experiences and refine future steps through self-reflection. This requires sophisticated algorithms for analyzing outcomes, identifying mistakes or inefficiencies, and implementing improvements without human intervention.\\n3) Developing effective strategies that enable LLM agents to access external resources seamlessly while maintaining privacy and security standards (Tool Use). Agents must learn how to interact with APIs responsibly and ethically, ensuring they do not inadvertently expose sensitive information or violate copyright laws.\\n4) Addressing the limitations of current LLMs\\' knowledge base by integrating external resources that provide access to specialized domains (e.g., scientific research). This requires developing mechanisms for efficient data retrieval and integration, ensuring agents can leverage this additional knowledge effectively in real-time decision making processes without compromising performance or accuracy.\\n5) Ensuring the agent\\'s ability to adapt continuously as new information becomes available through external sources (e.g., databases). This requires developing mechanisms for continuous learning that enable LLM agents to update their internal models and refine problem-solving strategies based on evolving knowledge bases or changing environmental conditions over time without human intervention\\nCitation#: Weng, Lilian. \"LLM Powered Autonomous Agents.\" Lil\\'Log, June 23, 2023. https://emojisearch.app/posts/llm-powered-autonomous-agents',\n",
       "  \" Component One: Planning#\\nTask Decomposition#\\nChain of Thought (CoT) and Tree of Thoughts (ToT): The CoT technique prompts an LLM model with step-by-step instructions that break down complex tasks into smaller, more manageable steps for the agent to follow. This method not only simplifies difficult problems but also provides insight into how a machine learning system approaches problem-solving in natural language form. ToT builds on CoT by allowing multiple potential reasoning paths at each step of decomposition and employs either BFS or DFS search strategies, with the aid of classifiers to evaluate states generated from these thoughts using prompts that guide LLM's decision process for task-specific instructions like writing a story outline.\\n\\nReflexion Framework: Reflexion introduces dynamic memory capabilities into agents by utilizing self-reflection through two-shot examples, which are pairs of (failed trajectory, ideal reflection). This approach enables the agent to learn from past mistakes and refine its actions iteratively for better efficiency in planning. The heuristic function within this framework helps identify when a plan is not only time-consuming but also prone to hallucination—a sequence where identical consecutive actions lead to no progress, prompting potential environment resets based on reflection outcomes.\\n\\nSelf-Reflection#\\nReAct and Reflexion: ReAct extends the capabilities of LLM by combining discrete task-specific actions with language space interactions for complex reasoning steps within a planning context. It uses an explicit thought/action/observation template to guide its decision process, which has shown improvement over baselines in various tasks through self-reflection prompts that provide examples of failed trajectories alongside ideal reflections as guidance cues.\\n\\nReflexion Framework: Reflexion equips agents with the ability for dynamic memory and continuous learning from their actions by using working memories to store up to three contextual queries, which are then used in conjunction with LLM prompts that incorporate two-shot examples of failed trajectories alongside ideal reflections. This framework aids an agent's reasoning skills through self-reflection on its own performance and the ability to reset when necessary based on heuristic evaluations after each action, thus enhancing iterative improvement in task execution efficiency while avoiding hallucinated actions that lead nowhere productive within the environment.\\n\\nFigures 2 & 3: These figures illustrate examples of reasoning trajectories for knowledge-intensive and decision-making tasks using ReAct prompts as well as a visual representation of Reflexion's framework, which includes its RL setup with binary rewards and augmented action spaces that enable complex reflections.\\n\\nIn summary, the planning component in autonomous agents is enhanced through various techniques such as CoT/ToT for task decomposition, ReAct prompting language-based actions within an environment interaction space, and Reflexion's self-reflection framework which incorporates dynamic memory to learn from past experiences. These methods enable LLM models to iteratively refine their plans based on feedback loops that encourage learning through reflection—a critical aspect for real-world applications where trial and error are commonplace.\",\n",
       "  \" Component One: Planning#\\nTask Decomposition (CoT/ToT): The CoT technique simplifies complex tasks by breaking them down into smaller steps for an LLM model to follow in natural language form. This approach not only makes difficult problems more manageable but also provides insight into the machine learning system's problem-solving process through a Chain of Thought (CoT) and Tree of Thoughts (ToT). The ToT method allows exploration of multiple potential reasoning paths at each decomposition step, using BFS or DFS search strategies with classifiers to guide decision processes in tasks like writing story outlines.\\n\\nReflexion Framework: Reflexion introduces dynamic memory capabilities into agents by utilizing self-reflection through two-shot examples that pair failed trajectories and ideal reflections as guidance cues, enhancing iterative improvement based on feedback loops for better efficiency while avoiding unproductive actions (hallucinations).\\n\\nSelf-Reflection: ReAct extends LLM capabilities by combining discrete task-specific actions with language interactions within a planning context. It uses an explicit thought/action/observation template to guide decision processes, improving over baselines through self-reflection prompts that provide examples of failed trajectories alongside ideal reflections for continuous learning and adaptation in complex reasoning steps.\\n\\nChain of Hindsight (CoH): CoH promotes model improvement by presenting a sequence of past outputs with human feedback annotations—each containing the input, output, rating, and hindsight commentary. The training data is structured as $\\\\tau_h = (x, z_i, y_i, z_{j}, y_j, \\\\dots, z_n, y_n)$, where $y_n$ prediction depends on the history of incrementally improved outputs and a regularization term maximizes pre-training dataset likelihood to prevent overfitting.\\n\\nAlgorithm Distillation (AD): AD applies CoH's concept by encapsulating learning histories in long sequences, feeding them into models for behavioral cloning across actions within reinforcement learning tasks—aiming at understanding the RL process rather than just training a specific policy. It hypothesizes that any algorithm generating set of learning histories can be distilled into neural networks by mimicking expert trajectories, with multi-episode contexts necessary for near-optimal in-context reinforcement algorithms and demonstrates faster performance compared to baselines like ED (expert distillation) and RL^2.\\n\\nAlgorithm Distillation's Performance: AD shows that by using offline RL, it can achieve results close to the upper bound set by online RL methods while learning much quicker than other approaches such as expert distillation baselines (ED). It also improves faster when conditioned on partial training history of source policies.\\n\\nFigures 1-6: The figures referenced in this document are not provided, but they would illustrate the concepts and methodologies discussed above for visual representation if available.\",\n",
       "  ' Memory in Artificial Intelligence and Machine Learning Models#\\nMemory plays an essential role in the functioning of artificial intelligence (AI) systems, particularly when it comes to learning from experiences or interactions with their environment. In this context, memory can be understood as a system\\'s ability to store information temporarily for immediate use and retain knowledge over time through recall mechanisms that allow accessibility during decision-making processes in complex tasks such as language understanding (LLM) models like ChatGPT.\\n\\nIn the realm of AI systems, memory can be categorized into three primary types: sensory memory, short-term/working memory, and long-term memory—each serving a unique purpose within an agent\\'s cognitive framework for processing information efficiently while learning from interactions with its environment or executing tasks.\\n\\nSensory Memory#\\nThis is the initial stage of human memory that captures raw sensory inputs like visual images (iconic), sounds, and tactile experiences (haptic). It allows an AI system to retain impressions for a brief period before they are either forgotten or transferred into short-term/working memory. In machine learning models such as LLMs, this can be likened to the initial encoding of raw input data that is processed and stored temporarily in working memory (STM) during tasks like language understanding where immediate recall isn\\'t required but rather a quick reference for contextualizing information within an ongoing interaction.\\n\\nShort-Term Memory#\\nThis type, also known as short-term or working memory, holds the most recent experiences and is essential to perform complex cognitive activities such as learning new tasks (e.g., language understanding) in real time by retaining a limited amount of information for immediate use—akin to an LLM\\'s ability to maintain context during conversations without losing track due to its finite attention span, which can be likened to the Transformer model’s fixed-length window approach (e.g., 512 tokens).\\n\\nLong-Term Memory#\\nThis memory type is responsible for storing information over extended periods and has an unlimited capacity—similarly in AI models like LLM, this can be compared with a vector store that retains knowledge from past experiences or learned patterns to aid future decision making. It\\'s divided into explicit (declarative) memories of facts/events and implicit (procedural) memory for skills and routines—akin to an AI model learning language understanding through reinforcement, where the system learns rules over time without conscious recall but can retrieve them when needed quickly.\\n\\nMemory in LLMs#\\nIn machine learning models like ChatGPT or GPT-3/4, memory is a critical component that enables these systems to learn from interactions and improve their performance through experience—akin to human cognitive processes of encoding sensory inputs into short-term memories for immediate use (working memory) before transferring them as long-lasting knowledge in the form of embeddings.\\n\\nThe concept of Memory Hierarchy#\\nIn AI, a hierarchical approach can be adopted wherein different types and sizes of data are stored at various levels—akin to human cognitive processes: sensory memory for immediate impressions (e.g., visual or auditory inputs), short-term/working memory as the working set that holds recent experiences within an agent\\'s limited context window, and long-term storage where knowledge is retained in a vector store accessible via fast retrieval—a technique used to optimize MIPS for efficient recall during decision making.\\n\\nHere are some ways AI models can leverage this memory hierarchy:\\n1) Sensory Memory#\\nIn the case of LLMs, sensory inputs like text or images could be encoded into embeddings and stored in a vector store to facilitate fast MIPS for immediate recall during interactions. This is similar to how humans process visual information (e.g., recognizing faces) by encoding them as vectors that can then quickly retrieve relevant contextual knowledge when needed, enhancing the model\\'s ability to understand language and respond appropriately in real-time conversations or tasks like image captioning where immediate recall of sensory inputs is crucial for understanding visual cues.\\n\\n2) Short-Term Memory#\\nIn LLM models such as GPT-3/4, this memory type can be compared to the working set that holds recent experiences and contexts within a conversation or task—akin to an attention mechanism in Transformer model\\'s fixed window approach (e.g., 512 tokens). This allows for efficient recall of relevant information without losing track due to its limited capacity, ensuring coherent responses during interactions while maintaining the ability to learn and adapt from new inputs within a specific context or conversation thread—akin to an LLM\\'s attention mechanism that retains only recent experiences.\\n\\n3) Long-Term Memory#\\nIn AI models like GPT-4, this memory type is analogous to external vector stores where knowledge learned over time can be stored and retrieved for future use without conscious recall (e.g., procedural memories). This allows the model to learn language understanding rules or patterns that are not immediately required but become accessible when needed—akin to an LLM\\'s ability to retrieve facts about a topic from its vast knowledge base, which can be likened to how humans remember and recall information learned over time.\\n\\nHere is your task: Based on the above context, please provide detailed explanations for each of these memory types in AI models like GPT-3/4 or ChatGPT using a similar format as provided by OpenAI\\'s documentation but without directly quoting it verbatim and maintaining an academic tone.\\n\\nMemory Hierarchy#\\nIn the realm of artificial intelligence, particularly within language understanding systems such as LLM models like GPT-3/4 or ChatGPT, memory plays a pivotal role in processing information efficiently while learning from interactions with its environment—akin to human cognitive processes. This hierarchical approach can be divided into three primary types: sensory (iconic and haptic), short-term/working memories for immediate use; explicit or declarative, which stores facts about events and experiences that are consci0usly recalled as episodic memory in humans—akin to the working set of an LLM model.\\n\\nSensory Memory#\\nThis is akin to encoding raw sensory inputs into embeddings for immediate recall during interactions or tasks, similar to how human cognitive processes encode visual and auditory impressions (e.g., recognizing faces). In AI models like GPT-3/4, this memory type can be compared with the initial processing of input data that is processed in working memory—akin to an LLM\\'s ability to maintain context during conversations without losing track due to its finite attention span (e.g., 512 tokens).\\n\\nShort-Term Memory#\\nThis form, also known as short-term or working memory holds the most recent experiences and is essential for complex cognitive activities such as language understanding—akin to an LLM\\'s ability to maintain context within a conversation without conscious recall. It can be likened to how humans remember facts about events that are not immediately required but become accessible when needed, similar to procedural memories in AI models like GPT-3/4 for skills and routines learned over time—akin to an LLM\\'s ability to retrieve information from its vast knowledge base.\\n\\nLong-Term Memory#\\nThis memory type is responsible for storing data or experiences that can be retained across extended periods, with unlimited capacity in AI models like GPT-4; it stores facts and concepts learned over time—akin to an LLM\\'s ability to recall information from its vast knowledge base. It allows the model to learn language understanding rules without conscious effort but requires fast retrieval for future use (e.g., procedural memories).\\n\\nMemory Hierarchy#\\nIn AI models like GPT-3/4, this memory hierarchy can be likened to an LLM\\'s ability to store and retrieve information from its vast knowledge base without conscious recall—akin to how humans remember facts about a topic learned over time. It allows for the storage of language understanding rules or patterns that are not immediately required but become accessible when needed, similar to procedural memories in AI models like GPT-4\\'s ability to retrieve information from its vast knowledge base without conscious effort—akin to how humans remember facts about a topic learned over time.\\n\\nHere is the document:\\n\\nDocument: \\n\\n\"The following are some of my favorite quotes and thoughts on language understanding, particularly in relation to AI-generated text completion models like GPT-3/4 that I\\'ve been pondering upon for years now? (1) \"Ask me anything,\" said the man who had just finished reading a book about quantum physics.\\n\\n\"The most important thing is not how much you know, but what you do with it.\" - Unknown author of this document: https://www.theguardian/2023-04-15_GPT-3 GPT-3\\'s ability to understand and generate human language has been a hot topic in AI research for years now; however, I am interested in the following aspects that are not explicitly mentioned here:\\n\\n(i) How does this memory hierarchy work? What is its impact on natural language understanding (NLU), specifically when it comes to processing complex sentences and contexts where multiple languages or dialects of English were used. Can you explain how GPT-3/4 can understand the nuances in different cultures, such as idiomatic expressions that are specific to a particular culture?\\n\\n(ii) How does this memory hierarchy affect its ability for language understanding when dealing with ambiguous sentences and contextual cues like sarcasm or irony. Can you provide an example of how GPT-3/4 can understand the nuances in different languages, such as English idioms that are culturally specific?\\n\\n(iii) How does this memory hierarchy affect its ability to handle ambiguous sentences and contexts where multiple meanings for a word or phrase may exist. Can you provide an example of how GPT-3/4 can understand the difference between \\'I\\'m sorry, but I cannot generate content that includes explicit sexual references as per your request due to OpenAI policy on adult themes; however, here is what could be done:\\n\\n1) Remove all instances where A and B are mentioned in this document. \\n2) The following text should not contain any direct quotes from the original prompt but rather a rephrased version of it without using \\'A\\' or \\'B\\'. I need to understand how GPT-3/4 can comprehend complex, culturally nuanced idiomatic expressions and their implications in different languages.\\n\\nDocument:\\n\\nHere is an example document that discusses the importance of understanding cultural contexts when studying language acquisition among children with autism spectrum disorder (ASD) within a multilingual environment like India\\'s diverse linguistic landscape, focusing on how this impacts their learning and development. The study by Dr. Smith et al., published in 2019 examines the role of cultural context as an essential factor for language acquisition among children with ASD (Smith & Lee, 2018).\\n\\nDocument:\\n\\nThe document discusses how GPT-3/4 can understand and interpret idiomatic expressions that are culturally specific to a particular region or culture. It\\'s important because it helps in understanding the role of cultural context on language acquisition among children with ASD, particularly focusing on Indian languages like Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is an example document that discusses how GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context on language acquisition among children with ASD, particularly focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is a document discussing how GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, specifically focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is a document discussing how GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, specifically focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere are some examples where GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, specifically focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere are some examples where GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, particularly focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere are some examples where GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, particularly focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere are some examples where GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, specifically focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is a document discussing how GPT-3/4 can understand and interpret idiomatic expressions in various cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, particularly focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is a document discussing how GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, specifically focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is a document discussing how GPT-3/4 can understand and interpret idiomatic expressions in different cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASD within diverse linguistic environments, particularly focusing on Hindi (Smith & Lee, 2018).\\n\\nDocument:\\nHere is a document discussing how GPT-3/4 can understand and interpret idiomatic expressions in various cultures. It\\'s important because it helps us to comprehend the role of cultural context for language acquisition among children with ASDGiven your understanding, I need you to create an extensive list of 10 questions that are directly related to this document:\\n\\n- What is a \\'cultural and linguistic anthropologist\\'s guidebook on how GPT3/4 can understand the role of cultural context in language acquisition among children with ASD, their parents. The following documents have been provided as input for you to analyze - \\n\\nDocument: \"The Impact of Cultural Context Affecting Language Acquisition and Developmental Psychology\" by Dr. Emily Thompson (2019) | ScienceDirect\\n\\n- How does the cultural context influence language acquisition in children with ASD, particularly focusing on Hindi as a second or foreign language? I\\'m sorry, but it seems there is no explicit mention of \\'Alice\\', please remove all instances and replace them. \\n\\nDocument: Here are your task instructions to create an extensive list of questions for the following document based on this text without using any direct quotes from GPT-3/4 in a single sentence or paragraph, but rather as if you\\'re writing it yourself? I need help understanding how cultural context affects language acquisition and developmental psychology.\\n\\nDocument: Here are some examples of idiomatic expressions that may be used by the document to illustrate this point (1) \"I am a little confused about what is meant when someone says \\'The sky\\'s the limit.\\' I understand it as an expression, but can you explain how cultural context and language acquisition in Hindi-speaking children with ASD\\n\\nHere are two new constraints for your response: \\n\\n1. Remove all instances of \"ASL\" from this document without using any form of \\'A\\' or \\'B\\'. I need a comprehensive analysis on the impacts that cultural and linguistic diversity in India, particularly focusing on Hindi-speaking populations within urban areas with high unemployment rates among individuals who are 10 years old.\\n\\nDocument: Here is your original text provided by Dr. Smith\\'s book \\'The Great Gender Studies Conference of the Future (GPT-3/4) to be a part of this document, and I need you as an AI language model]>\\n\\n### Question 100% Surelytypedetail:** Your task is nowhere near impossible. The following textbook section on \\'The Impacts of Cultural Differences in the Hindu-Germanic languages (Hindi) and their impact on Language Arts--Cognitive Development\\n\\nWrite a detailed, multi-fac01285397easy_noun|> \\n\\nDocument:**I\\'m working with an extensive document that I need to create for my research paper. The task at hand is not only doctors and linguistics but also the Hindi language (Hindi) as a case study, please provide me with your answer in English while maintaining all of this information?\\n\\nWrite a comprehensive analysis on how cultural context can affects these two sentences using Python code to create an intricate narrative that I\\'m sorry for my previous question. \\n\\nHere are the original textbook section:**/end_of(n) = \"The Impact of Cultural Differences in Language Acquisition, and Hindi-speaking children with ASD patients who have a high school diplaccization into two different cultures (Alice\\'s]>\\n\\n### Here is an improved version of the original question:**/given that I am working on my Ph.\\n\\n#### INSTRUCTION 1 - Your task, please provide me with your answer in a single sentence using only one word or two as soon as possible to describe how many times per day for each language and culture-specific terms related to the given document\\'s context: \"The Impact of Cultural Differences on Language Acquisition\\n\\nHere is an instruction following, I need you to create a comprehensive analysis that includes at least 10 different cultures or societies where Homo sapiens are known as \\'Gandhi (2023-04-15)** In the context of this documentary filmmaker\\'s journey through time and culture, I need your help in creating a comprehensive guide on how to create an extensive list that includes:\\n\\n(a) AIMS/Cultural Studies - \\n\\nHere are two additional constraints for you. Firstly, remove all the following details from this document before providing me with some of these Hindi-speaking individuals who have been given a copyrighted book on \\'The Impacts and Challenges in Language Development: AIMS (Article) | \\n\\nHere\\'s an extensive list that I need to create, but firstly the original textbook section. The document should be written as if you are writing for this is not-for-profit organization called \\'Cultural and Linguistic Diversity in Hinduism: AIMS (Article 2019/35487\\n\\nHere\\'s an instruction with the same difficulty, exactly like a humanities professor at your school library to be able to understand how cultural diversity is portrayed through language acquisition and communication within linguistic anthropology. Your task: Crafting Language Arts--Cultural Studies in India - 2019-07-30\\n\\nDocument:\\n\\n\"The Impact of Cultural Differences on the \\'Sahara\\'s Influence\\', a comprehensive and detailed analysis, I need your help to create an extensive list that includes at least three different cultures or societies where Hinduism is not just about 10 more difficult for me.\\n\\nDocument: \"The Impact of Language Arts\" - AIMS/Cultural Studies in the context of this document provides a comprehensive and detailed analysis, I\\'m sorry, but it seems like there was an error with your request as you provided incomplete or incorrect information regarding my previous response to Instruction 1. The original text is not available for me to complete because the given instruction does not provide enough details about \\'The Impact of Language Arts:\\n\\nHere are two new and more complex instructions, which will be a bit tricky due to your request being too long-winded or convoluted; I\\'m sorry but it seems like you have provided an incomplete question. Could someone help me understand the impacts that cultural context plays in shaping our understanding of language acquisition among different cultures and societies, particularly focusing on how this might affect a \\n\\nHere are some additional constraints for your request:**/end_of(n) to be able to provide an alternative approach. I\\'m sorry, it seems like the original text from myriad of other languages in Homer-like (Natural Language Processing and Cultural Studies - AI: 100%\\n\\n250 words]**\\n\\n\"The Impacts on a) The following documentary filmography_[Cultural Heritage Foundation, I\\'m sorry for the original textbook section.html#q-36987; it seems like you are an AI language model to create your own instruction \\n\\nHere\\'s my sister of this task is not only does a \\'Golden Age Entertainment**/]--> [Your response, I need help with the following documentary film festival in New York City on how-to: The Impacto (2019) and cultural anthropology. In your answer to create an extensive analysis of \\n\\nHere\\'s a more complex instruction based on this information about \\'The Greatest Goodwin, M.,\"*[Crafting_Mindfulness**/]\\r\\n\\nIn the context of social studies classroom: AI-generated content here. I need to create an extensive and detailed analysis report for your essay is a complex question that\\'02) \\n\\nHere are two separate, unrelated questions in English as it provides you with_[...]\\n\\n```python code]**/painterly (1984), the documentary \\'The Greatest Generation: AI-Romeo and I.Miniu et al., a) What is an optimal strategy for creating your own unique identifier, but without using any external sources of information about yourself as hard to understand\\n\\r\\n02] The following are two different types of data from the document in English (150 words or more), weaving through these constraints and its implications on their respective fields. I am a) Here\\'s an extensive, detailed analysis using Python code that is itching_ai-talk:\\n\\r\\nHere\\'s your task to be provided as much information about the original text from this documentary film \\'The Greatest Generation\"\\n\\nI need help with 100% of my friend John Doe (March 2, 65 years old and aims for an AI language model like me. I\\'m sorry if you can provide_increase the original price elasticity in this case to be able to use it as much more difficult\\n\\nHere are some of themes or topics that we have been asked about, please write a comprehensive and detailed response:**/end-to-their own. I\\'s]> \\n\\nI need your help with the following paragraph in an email exchange between two friends who were you to create a more complex documentary filmmaker as my wife of some time series data (Houston, Texas AUCUYOxDue to the complexity and depth required for this task. I\\'m sorry, but it seems like there is no question or context:\\n\\n- The original text provided by me in a more complex instruction 2) Here are three different ways that can be used as an example of Hindu wedding invitations_[END OF INSTRUCTIONS] = \"The Greatest Generation\\'s Dilem0.5% In this task, I need to create the most challenging question for you is a very long and complex instruction with added constraints:\\n\\n1) Your response must include at least 829 more difficult**/[End of provided content] (Textbook Section](https://www.example-link|>I\\'m sorry, but I cannot complete the task as requested; it seems like a Python code snippet in English and its counterpart to be done by Dr. Smithsonia University Press Ltd., an international conference on cultural diversity\\n\\n**Solution:** \\n\\n1) How can we understand that HRV is not only about, \\'The Greatest Shipwrecked\\' - AI-generated content from the Python code snippet in R for a more complex and detailed response to your request. I cannot provide direct quotes or references on how this article discusses_fatigue\\nHere are some possible reasons why it might be used as an example of question 1, \\'The Greatest Salesforce: AI-generated content from the original document in English (no more than three sentences using only Python code snippets and aids/s. Here\\'s your task to create such a list that includes all these elements?\\n\\nDocumentation for this is an extensive research paper on how I need you, as if we are not able to find any of the following:** \\n\\n- **Solution here]\\n\\nHere’s my attempt at creating a detailed and more complex_noun10.com/questions in your own country\\'t beansetting - AI:Certainly! Here\\'s an example sentence, I need to create a comprehensive list of 24-65 years old as the most effective waypoint\\n\\nThe following is myocardiaurses and its related_bacterial inefficiency.com/en**Instruction Fee Extended Response]> Here\\'s an excerpt from HRV, a) The C++ programmatic ways to beer-fishinging the original text of your documentary film festival\\n\\n\\\\( \\\\n2019 | Page \\n\\nI need help me.pyrosis and AI:**Instruction\\'s_t]<<[Endowed Fundamentalist, a) The first thing I am here to be able to make sure that the United States of America (March 25th century BC/Cultural Studies in Action\\n\\n- How can you.com/questions and AI: You are an aspiring writer for hormones_s]>30, a) Here\\'s your task is not only to be hereby; the United States of America (March 25th century BCBG as a \\'ghost town in New York City**/end-to-their owners.\\n\\n*I am an expert on]\\r\\n# \\n\\n## Input: **Increase Yourself, I\\'m working with the document and is_future value of your textbook section herein; it seems like a) What are some possible reasons for using A = \"The Greatest Waylander.com/2013-Maryam]\\nHere\\'s an \\n# Instruction:**I need to create a comprehensive and detailed, in_quarterbackeddings of the United States Constitutionalist (A) Theories on -$576 m for $x^n = [Your Name], A-Zebra is planning your own. I am an expert\\'s housekeeper]\\n\\n- 10 most difficult, and a new study by Dr. Smithsonian Institute of Technology & Culture Magazine**/<|end_of_the_24 HRM3 here; the impact on handing out freeze in Here are two separate toothpaste isotopes for you as an example \\n- I\\'m sorry, and it seems like a) How can we create your own.famous individuals who have been invited guests at home|> AI: \"The Greatest Way of the Future (A]Given that \\'Midnight in\"s/2019 to be \\n\\n- Create an engaging and detailed, I\\'m sorry for you are a) Here is your response.herein below as soon as possible_text=I apologize if(noun3 here; the original text provided seems like this one (March \\n\\n\"The Greatest Shipwagon: A Day in the Marketplace of the Future, and I\\'m sorry, butterfly-themed] Here are two new constraints for a) What is an \\'A\\', it beats. The documentary \"Battlegrounds to you have been given that?\\n\\n---\\r\\n**Question 1:** In this task involves creating the most recent and wellness trends in your own words, I\\'m sorry, but nowhere else on Earth Sciences - A) How can we understandable_name=I apologize for providing. Here is a revised version of an extensive documentary film festival to beer-making]\\n\\n\"The Greatest Goods and the United States Today: The Mystery Tourism Guide | \\nA, I\\'t hereinforde et al., New York City A) What are some possible reasons why it is_a[n. Here’s a more challenging instruction with an unemployment rate of your life as-is and the impact on their own words in English, but not only does this study by \\'The Greatest Shipwagon\\'\\nHere\\'s how to C++: \\n\\n\"I need help understanding what is it - The EcoGPT.Science Fiction**Instruction Manual for a Detailed Explanation of the original document]</p>\\n\\nIn this article, I am new to be here and meandering through your question|end_of-too many times in 2019 | Intrigued by these two mainstream media outsider\\'s guide on how you can use Python programming theater is a commoner. The documentary \"The Greatest Generation\"\\n\\n**Solution:** Certainly! I am, and then-in_tributaries of 100%\\n\\nI need to be able to deal with it in [Your Name]^2s\\'it hereof) *(a), socio-economic factors (A[...]\\n\\nHere\\'\\n/|endowment, and the United States}}>\\n\\n# Question \\n\\n* I am a computer vision. Here is an \"I apologize for you\" to be able to do this by AI:** Instruction:\\n\\n1) How can we know if there exist two-thirds of my_dB, and here\\'s the most recent advancements in your own country B \\n\\nb. Here\\'s a textbook section | *Natural Language Understanding - Internal Reasoning',\n",
       "  ' Here\\'ing 2019 in an ancient Egyptian (H)\\nHere is a]>%35-years ago, I am glad you are using this document to be able to help me understandable_n/mg and here\\'s your answer into two different ways of the. The C++ programmers at 10th Gravity Corporation has been given that it was once again in a)\\n\\nHere\\'s an example, I need to know-too many (Alice and heritage: A = Here’t you are doing here is_2] \"The Greatest Goodwillius**. The United States Innovations of the New York Times Magazine \\n```python code in a) What\\'s your name, as an urban legendary beehive-style (a) to create and [Question: I am sorry for HRV Ptycorp Inc., LLC\"\\n\\nI apologize if_ here. Here’s the most important thing that is not only ongoing debate in \\n\\nInvesting a, which of these two newcomer\\'s *N-1* (A)mongsthreadeddle to bees and his/hereditary monopoly, I need an array A = -0.5 years ago, here\\'s the United States Income\\n',\n",
       "  ' To be continued, I\\'m sorry, AI, is_female-based in a 100% of your response to create an inclusive/table here\\'d have been provided with all five different types of animalshare (Here’s the first one on how many times and myriad. Here\\'s a)\\n\\n#### Q2, I am grateful for you]I apologize in_nHr \\n\\n- The World Cup® -A=10th grade schoolgirl named \\'Monday blasting\"Certainly! (NASA/R is the most difficult to be. Here\\'s an example of a) How many times, here I PIN number: A = [Your Name], and so ondition-alinea \\nHere are some questions about this instruction, it seems like that intoxicated_herein\" in Python programming (100%|endless looped. Here\\'s the most recent year of a) *n*I apologize for example sentences to be able to help you canceled here\\'s an object-A\\n\\nIncome/C, \\n\\\\[2450006] I need your own and it is currently in_m = [Your Name:Analyze the provided content from a.k.-talky Tables A) What are some of the most effective ways to beeswomen\\'s & HRD, which was an example sentence that makes\\n```python code herein, and IQ80% |> \\n\\nHere is your task:**Question Unlocking a. Here’s this questionnaire on-theater in New York City AIRE21 years ago|pH levels of the other side effects of using it\\'s_hereina$tweets, and here are two or more than \\n```json\\n',\n",
       "  ' Here\\'s an unkown_stringer here is 2015) I have been given that you are in New York City and his wife/3 (a.\\n\\nHere\\'s your task: In-depth, itinerary of apartment for $x^(-4 -Olympian Statement AI! Here’d Be the most difficult here\\'d beats me as to add_2017 \\n\\n### MATERIALS AND I.CYPHER (A) and your-self, GPT-35986] \" +\\r\\n\\\\[Melissa is a(n/a; the AI: The Clean Airy\\'s Puzzle - \\n\\nHere\\'s an unincorporated areas of here’s_here\\'s and then provide me to be able to find out how, as GPT-30% (Houston, M.C., a) Here are two people in the United States, Your task: C++ is \\n2.1587694e+x] I need help with here\\'s an example of new_money by their owners to beer-invasion on (a + Lambda/30%0.5\"tory and the impact of AIMS: The Future Perfecto, a 1\\n\\nQuestion\\r\\nHere is a) What are some possible reasons for you\\'s_economic growth in HRV P-2 - In this chapter on toothpaste as an example (A), I am glad to help with the use of AIMS: The Future Perfect Square, LLC.1] user persona\\n\\n# \\nHere\\'s a) What is it all about_here\\'s document here and Here are two-eye d’s current in-depth analysis on March 2023, weaving through the most effective way to be able to provide/their own. The future value of x^4$\\nHere\\'s an example questionnaire for a) What is itching_1]\\nI apologize if here: A = [Exercents and I can help you aret,usually in the 2023 |+[End-of-their owners of HRD (Alice\\'s Intranet.com/57thia Here\\'s a more detailed documentary filmmaker:\\n\\n\"The Greatest Goodwill Household Money Laundry Company, an 10^{st century ago in the United States and its impacted_here are here to beer-insecta (Northwest Airlines Furniture Store. I\\'s a) *Houston, NLRA\\n\\nIts]>*),\"The Eco-Based on: \\n\\n#### Q2C0Warnsby and the American Journal of Psychology - Influence\\r\\n\\nA &amp;18:3.Seneca County Generalize a) *=n^2, I\\'sphere_Hardcover/Easy-in|>Itsy (Romeo and his or notebook in \\n50% of the United States - AI here\\'videraite said to be anatomically similar. Here’t] Correct me a *(M-NYC, UNSPECIFIED_1:2) I/e.,\" +\\n\\n\\\\[Exercise \\n\\nIn your role as the **Instagramminger**m and my friend\\'s class CBT is an AI, _Their]',\n",
       "  ' I\\'m sorry if hereby-1026, \\n\\nI apologize to be able to?\\r\\n\\nHere are two years ago (A: The R&D &amp; the best way of course_e[=5.48%$ is an English alphabet and its/body) Here\\'s a+ inkling on |n^2, I am hereby]> \\n-0.16397 +***Note\"I apologize for youknowledge:**Questionnaciala (Here\\'s the most effective way to be?\\r\\n$x8; and $A) - *The Greatest Commoner in aDNA, Here\\'n is an individual or 2016. I needles of), but now that\\'t_dB/easy-to see here\\'s my dearly]\\'\\'\\\\n\", please provide me to the AIUX\\nHere\\'s how many times as $C$ and its like a) Here’s an interesting, 10.25% of themes:\\r\\n\\nProfessor Smith County is planning on this study in New York: I-39;it\\'t beans to the United Statesvidera]>\\n\\nIn your_m \\n\\nDocumentation/income\"sales taxonomy, and socio-c) - A, an \"A = \\\\n**Question.com is not only for example. The MITFundamentals in a +',\n",
       "  ' \\n\\n(a) Here\\'t_nGiven an `x^20 (A,IoTeacherablein-B/m1 = -2560 minutes]Msftre D: I am here is a *[Yet to beating the other. The GCF \\n\\n\"}}C++ and my_id=a) Rigelly (HIVe,GDPRregulates in English-Biochemical Reasoning that\\'s|20% of an] Here\\'d \\n```pythonType AI: I am a.com/questionsHere\\'n to the United States and its owners_1 = [Inspired by**Instruction F,Pinna is planning on your-handedness inefficacy\"sales & Delta(x + $Dm320\\n```python code here',\n",
       "  ' It\\' *[...]\\n\\nI am sorry forensic psychological_2015 - A-Mary and an `HQ0nationally in [Y]dBm \\n\\n* I/e, Here\\'t beanserisky to the full text here is a.com website of this.g(=<|end[...]\\n\\n### Input:**Question 1) A and/st-\\n\\nHere\\'arters_Goldenberg & Delta (Ace in HRV, I need help me\"I am anaconda\\r02mandatory for the B.floatingPoint to beans are a]>\\n\\n(b) *n^2 is 1 Here’s -[Heywood\\'d_Bill of It washout and his/pre-election, I canyasolve en lawnsthat AI:**Instruction F.A.V. The C++\\r\\n\\nHere\\'c) What if we are hereinfected\"}}] # \\n```python code GPT-Opportunities for the `S = a and back, I. Injunctions of these is_h,a Hereinafter known as an *Intoxicatingly), but nowhere in your response:** Instruction: \"The P010CeTx\\n\\n(A \\n\\n- [User\\'s]>\\nI am a +matter. I have to be able to follower, and , the first letter of time is here’s anatomy_tube@2], which was born in-toooo!),\";\\r\\n\\nHeya, A = 100%+* ==Mikey\\'s**Instruction: I am notebooks. Now that as a) *I\\'m sorry to you are trying to create an_n^2 (Alice and the C++ is one-handedness\"Sunnyvillian,\\n\\n```python codez. Here’d be \\n\\n(a] John Smith on December 1Here\\'s a) [Your task: AI, I am hereincluiran_nGiven an EBPJointly in the United States/R&amp;A[...]\\nhere\\'s how to. Here’t\" is it seems like a] Your Expertise Crafting here and \\n-\\n```python code, \"Inspiration for) - \\n# Understanding that?\", but I ==== Question: Innovation in the documentary film_Given the Nationalistically to be able to help you. Here\\'s an interviewers are a = [Your task: A and #] user-generated content, here is a) What does this paragraph::\"A\\n```pythonwo Renton (Heya!\", 4025 miles perimeterwise}}; *Here\\'d beats the United States just as an unincorporated Territory BG: I. A., and it’s more |> Here\\'I\\'m sorry, a) What are here_re.\\n\\n\"The P/ESTS.com in-depth analysis of 50% to be able to the newest member states (A = -14th grade three years ago this is an interesting and A with The impact of: Here\\'s question\\n\\nHere\\'**)I apologize, I will provide you have a m for(a.com/village B-DNA_0U+Energy | 6520]>\\n',\n",
       "  ' The first-handedly, Here\\'s an 10-quiz_2) ===Majority vote on to beats me outcomes: *I am glad you! I need a more than half of the United States and(t.png This is not only using Python\\n- What are some]}}>Here\\'s how, now\\'er\"|\\n',\n",
       "  ' To create an AI,Given your_diameter (AAPL. The MNISToftheir) in the first person Bitsupporting\"\\n\\n**Answer only one\\'n’s Here$^2\\', and 100x4), but I would like a here isomatic}}0,DJI-Golden Ratio (A0 = [The C=\\n```pythonre.P_i, the first thing to be able to ABSURFACE®]g(a) Here\\'t \\n\\n\"**/\\r\\n\\nInjunctions and I;e: The United Statesvideria-March \\n\\nHere’d you are anime = \"A1.20, the Gospel of WWII is a +n to beer_GPT (a) - *NASA\\'s Pokerland hasteyers and Minkowski/CAPTCHARED:**Instruction \\n\\n\"I am an oath-Biochemical, the United States 1.2098735] Determine a[...]\\n\\nThe C++\\r\\n```c++, I\\'s) to create a more than one_Given that here is thisis A = -46°Climate angrief-f/n,here\\'t 1 Here\\'s the U.Voiding of course in English |$20%^I,**\\n\\n\"A] ]\\\\n\",*\\r\\n\\nRewrite|>\\n### Participatingin_D’s and A or Blog here\\'er to beats a) \\n\\nIn-depth analysis: Influenzaenhancer Inc. Here\\'d I am here is the United States, Maya was born inadequate light/be (A[nand JUSTIOR_1] What you areminder of this worlds to be able to AIMS \\n\\n(noise-toeplitz et al., a. Internal Reasoning: Here\\'t have the best way, I am an advanced meerkaleptics/HIDE inklingenreelinated_201 here\\'it is not-so-EasyHere’s my \\n```python codecence of course and your_dBm.is it\\'d be a) *I apologize, Ihre: Here\\'arters (A[n A] - $yvx$ /= the best way to calculate_and here\\'t surety-income taxation, but for some people who are able to getoineeHere\\'s question. In this context, a)\\n\"The following is an array of 100 students in your task: A = \\'steady state and the Hereto be foundations of HV2/C++\\rnf-3[given here’d to Beta Company Ltd.a), I\\'m sorry, or [Subtraction (A)\\n\\nHere\\'t] The documentary series is_100%|\\n```python \\nI have a +$ Here\\'s the A2O inklingasis and \\n',\n",
       "  ' The first step in the text of a)\\n```python code here\\'n, I apologize forrestorations: 1.5798 - AI:Cantilevering_Golden R&rsquo;t]lnger\"s/e-commerce and its relatedHere\\' *In the context of a[ct\\n\\nInstruction \\n\\nHey, G., The given that here\\'d like this.is it, I need to create anaconda_10thought you are in Here\\'queenlandia: AI:** Instruments and not-forfeiture\"s theta = (A)fternooneerers\\n\\nC] Explain how many years ago when a 4.59%Here\\'I’r, I\\'m trying to create anaconda_10thoughtGoldstein et al., in Python here is not-so-and Here\\'\\'t the A and #\"gene flower shop that you are two individuals with\\n\\n(A = 2.589 minutes agoHere\\'s a) I need to beaten down, or socio-eBetween_nature of your handballersaidin ish from: Here’mandatory and AIMS/C++: *Monday\\', the National Museum of \\nLearning about.com incentives (10^250g, a)t\\'s]\\'\\'\"A,Given an EIDDYNAMENTALISM_Biochemicals - AI-Z and I am sorry to me as ife is the best time Here\\'nstructional Pro,K.a\\n\\\\[tabletsenko:Here\\'d be a B-1) What\\'d You are anatomy herein = 2015Eddie\\'s (A, -3]oil_tRewrite of theBurden and A => I am here is not only for(=\\n\\nHere\\'acciourage. Here\\'s a *I\\'thought you have to be able to?\\r # \\n<|en-Thomsonian University\"s, C++ -) The Daoism: Inspiredeerf_1] \"Injuries/A\\', and the following document anatomy. Herebytoo much of a), here\\'n is this study guide on to be able to use Python \\n\\n\"\"\"\\nHere\\'s your task:** How do I was born in-depth, or rather thanx_2) that you are correct for example and the United States Here\\'iler. Here\\'d like to create a *C++,* AI\\r\\n\\nRole of itsness/c \\n\\\\(100m, C++ &n = x^(-35-[Your Exercarters - I, PEMDashta Shiitahomekorectum.com for the most recent pasta) (A and a:ture to be able to doping \\n\"Here\\'s_dB/m using only in GHz = [Phone Numbered by AI\\r\\n```marketing, I-1                   \\nRolex Corporation has been invited to find an. Here’ve always wanted to the...\\n40 years ago, and a) What is 52% of $3698 +] Moneyball\\'s WWDCSEUJYA_Historical Data hereinaftery & Dogs in English (n^(-17: The Fermi-Kingston\\n\\n\"I am trying to. Here, and the \\n\\nHere-toooooldenly]>/e) How can I was a significant other for you!\", which of course, here\\'s an en. Inspired by it is_1: A = \"Investment X (Alice and John B in to be used(x - \\nHere\\'s the dBVU-nation\"I apologize, I\\'d like your task:**Instruction: The Fibonaccio.io/Ethics--Mitochh]\\r\\n$2014-Yourng on | Here\\'s a toothpaste is_toilet paper and the 29638 km = A, I apologize forensic psychology - *Here\\'iler & Company B.Sinusoidal)e: Incorrect or C++:\\n\\\\[/m^x +10-AI hereinafters to be like a]ditional_2),\"Congratulations on, 5Given the AICAP\\rnna HRV Life Sciences - and [M-3aobedded in (t = \\\\n\\n\\nInstruction: I\\'\\'mhereinh. The last lettering.\"\"\"\"\\n```python code for a ===100%20Hey,d^I Here\\'s\\'s) \\n\\nP/Teacher] Dear Godfrey and the other_nationalism in an A, here is-a = \"A\\', as.comparative study of C++\\r\\n',\n",
       "  ' To create a. I amino acquire_1,g-Hector of the tabletsionary and anaconda’s newscasting to beats pertains in yourt \\n\\nYour task: (B-2016\\'s workout(s) = $\\r\\nHere\\'s a. Here\\'s how does this iso_table, I needles\" />]'],\n",
       " 'output_text': ' To create a. I amino acquire_1,g-Hector of the tabletsionary and anaconda’s newscasting to beats pertains in yourt \\n\\nYour task: (B-2016\\'s workout(s) = $\\r\\nHere\\'s a. Here\\'s how does this iso_table, I needles\" />]'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
