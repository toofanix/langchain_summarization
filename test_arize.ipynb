{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Why don't scientists trust atoms in quantum mechanics?\\n\\nBecause they make up everything, even their jokes! But seriously, why did the atom break up with its electron friend? Because it felt like there was too much repulsion going on between them and not enough attraction to keep things stable.\", response_metadata={'model': 'phi3', 'created_at': '2024-07-09T12:26:21.8189148Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 16516511700, 'load_duration': 15667132400, 'prompt_eval_count': 12, 'prompt_eval_duration': 40714000, 'eval_count': 66, 'eval_duration': 806011000}, id='run-e77a98b0-f6e2-4665-bfc8-5be8d24e5e6b-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model='phi3', temperature=0.0)\n",
    "llm.invoke(\"Tell me a joke about chemistry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [langchain_text_splitters.base] Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='stuff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This document provides a comprehensive overview of the latest advancements in language modeling, particularly focusing on Large Language Models (LLMs) and their capabilities. It highlights several recent studies that explore various aspects such as steerability—the ability to guide LLM behavior through prompt engineering or external feedback mechanisms; agent-based approaches where models exhibit autonomous decision-making abilities, often with self-reflection components; in-context reinforcement learning techniques like Algorithm Distillation for enhancing model performance without extensive training data.\n",
      "\n",
      "The document also discusses the integration of LLMs with external tools and knowledge bases to augment their capabilities—a trend exemplified by projects such as Webgpt, which leverages human feedback in real-time question answering scenarios; Toolformer that enables models to teach themselves tool usage for task completion without explicit programming.\n",
      "\n",
      "Furthermore, the document touches upon emergent scientific research abilities of LLMs and their potential applications across different domains like chemistry (ChemCrow) and autonomous agent behavior simulation (Generative Agents). It also mentions advancements in vector search technologies that facilitate efficient similarity searches between large datasets.\n",
      "\n",
      "In summary, the document encapsulates a snapshot of cutting-edge research aimed at empowering LLMs with greater autonomy, adaptability, and proficiency across diverse tasks through innovative approaches to model steerability, tool integration, reinforcement learning, self-reflection mechanisms, and efficient information retrieval.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(docs)\n",
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2836 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lilian Weng's June 2023 article \"LLM-powered Autonomous Agents,\" published on her GitHub page, examines the use of large language models as autonomous agents. The paper discusses their potential in various applications through prompt engineering techniques like Chain of Thought and Tree of Thoughts frameworks that encourage reasoning within LLMs. Weng's work builds upon previous research by Wei et al., Yao et al., Liu et al., Shinn & Labash, Laskin et al., Karpas et al., Nakano et al., Parisi et al., Schick et al., Weaviate blog posters, and others. The article also references tools like ScaNN for efficient vector similarity search and AutoGPT as well as GPT-Engineer GitHub repositories that facilitate LLM interactions with external knowledge sources or planning tasks. Weng's research aims to enhance the steerability, adaptability, and problem-solving abilities of autonomous agents powered by language models in NLP applications.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce')\n",
    "result = chain.invoke(split_docs)\n",
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The more I amendment:\n",
      "\n",
      "The job of a 1 [https://enactments\"%2C and your role-seafood_Based on this is anatomy infection rate (30 minutes ago | https://www.com/apiary, the National Geographic. The task remains unchanged]}}>\n",
      "\n",
      "I's job: \n",
      "\n",
      "### This one of myriad reasons for a) A personality-based treatment_Based on your owners to beatingtonia and socioeaninger (100%2f3.\n",
      "\n",
      "The more I needles, the U.S.IZE:\n",
      "\n",
      "A patiently\" in English | \n",
      "\n",
      "### Instruction>\n",
      "What are some of these days ago_BEGINNELove-Craft a comprehensive and then wearing gloves/puzzle) is an HTML5042, to the company's current = \"The Jobseasers. The job title: \n",
      "\n",
      "1. What would you like to know more information about meals_Based on your name as a personX\", which of course, and I am trying to create a simple Python code-based on this page is itching) +50 years ago | January \n",
      "\n",
      "The following yearning for the other hand. The job: A:\n",
      "\n",
      "### Instruction in anaconda_B2c9d86 mRNK, and I understands that as a human-based on this exercise is to ensure that each childrens' email\"I am sorry, Bellaville, the FBI. The job title: \n",
      "\n",
      "Your task washington County (a) infection_Bill Gourley et al., ants and I need to paying attention to a non-fiction/buyers of this instruction is itcheye's work done]></|endclaim, the job. In your response:\n",
      "\n",
      "### Chatbot: \"I apologize for more than \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='refine')\n",
    "result = chain.invoke(split_docs)\n",
    "print(result['output_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
