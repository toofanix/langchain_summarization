{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Why don't chemists trust atoms? Because they make up everything!\\n\\n(Note: This joke is light-hearted and not intended to trivialize the importance of chemistry or scientific research.)\", response_metadata={'model': 'phi3', 'created_at': '2024-07-06T19:38:44.579977Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 4341648001, 'load_duration': 1665569, 'prompt_eval_count': 11, 'prompt_eval_duration': 324875000, 'eval_count': 45, 'eval_duration': 4013354000}, id='run-f7e69257-083f-4de1-878a-fd292dd8a404-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model='phi3', temperature=0.0)\n",
    "llm.invoke(\"Tell me a joke about chemistry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Type as Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Title: Enhancing Large Language Models with Planning Proficiency and Tool Integration for Improved Steerability and Prompt Engineering\n",
      "\n",
      "Abstract: This paper presents a comprehensive study on the integration of planning proficiency, tool augmentation, and steerability in large language models (LLMs) to enhance their performance across various tasks. We introduce novel methodologies such as LLM+P for optimal planning proficiency, Reflexion for autonomous reasoning with dynamic memory, and Toolformer for self-teaching through tools usage. Additionally, we explore the synergistic effects of combining language models with external knowledge sources (e.g., MRKL Systems) and discrete reasoning (e.g., ChemCrow). Our contributions include a detailed analysis of adversarial attacks on LLMs, advancements in prompt engineering techniques, and an evaluation framework for assessing the steerability of these enhanced models. The paper concludes with insights into future research directions and potential applications in diverse domains such as scientific research (Emergent autonomous scientific research capabilities) and interactive simulations (Generative Agents).\n",
      "\n",
      "Keywords: Large Language Models, Planning Proficiency, Tool Integration, Steerability, Prompt Engineering, Adversarial Attacks, Reflexion, Toolformer, MRKL Systems, ChemCrow, Generative Agents.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='stuff')\n",
    "result = chain.invoke(docs)\n",
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Type as map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f804729a6da45e293fb8b5c40bad06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7863b50b4e474e8eb34cd60422582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40e8c8a8bd24a84b8b951c363e6ecf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6dfd2631d54f56a8638fe69af58e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf12ca3969e84a7abea964303e109447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This paper explores enhancing large language models (LLMs) with improved planning proficiency, tool integration, and steerability. Key contributions include the LLM+P framework for reinforced prompt engineering, ScaNN's vector similarity search algorithm, Reflexion's self-reflective autonomous agent, Toolformer's architecture for learning tool usage, API-Bank and ChemCrow benchmark datasets, EASRC's autonomous scientific research capabilities, and Generative Agents' simulation of human behavior. These advancements aim to create versatile LLMs capable of complex task execution in diverse domains.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce')\n",
    "result = chain.invoke(docs)\n",
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Type as Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Title: Enhancing Large Language Models with Planning Proficiency and Tool Integration for Improved Steerability and Prompt Engineering\n",
      "\n",
      "Abstract: This paper presents a comprehensive study on the integration of planning proficiency, tool augmentation, and steerability in large language models (LLMs) to enhance their performance across various tasks. We introduce novel methodologies such as LLM+P for optimal planning proficiency, Reflexion for autonomous reasoning with dynamic memory, and Toolformer for self-teaching through tools usage. Additionally, we explore the synergistic effects of combining language models with external knowledge sources (e.g., MRKL Systems) and discrete reasoning (e.g., ChemCrow). Our contributions include a detailed analysis of adversarial attacks on LLMs, advancements in prompt engineering techniques, and an evaluation framework for assessing the steerability of these enhanced models. The paper concludes with insights into future research directions and potential applications in diverse domains such as scientific research (Emergent autonomous scientific research capabilities) and interactive simulations (Generative Agents).\n",
      "\n",
      "Keywords: Large Language Models, Planning Proficiency, Tool Integration, Steerability, Prompt Engineering, Adversarial Attacks, Reflexion, Toolformer, MRKL Systems, ChemCrow, Generative Agents.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='refine')\n",
    "result = chain.invoke(docs)\n",
    "print(result['output_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
